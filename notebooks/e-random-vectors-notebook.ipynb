{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Appendix E - Random Vectors\n",
        "\n",
        "Joshua French\n",
        "\n",
        "To open this information in an interactive Colab notebook, click or scan the QR code below.\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/jfrench/LinearRegression/blob/master/notebooks/e-random-vectors-notebook.ipynb\"> <img src=\"https://raw.githubusercontent.com/jfrench/LinearRegression/0ece3fee82ea5e6188728023edf1dfa8318e4d48/images/qr-random-vectors.svgg\"> </a>\n",
        "\n",
        "# Random vectors\n",
        "\n",
        "## Definition\n",
        "\n",
        "A **random vector** is a vector of random variables.\n",
        "\n",
        "-   A random vector is assumed to be a column vector unless otherwise specified.\n",
        "\n",
        "A **random matrix** is a matrix of random variables.\n",
        "\n",
        "## Mean, variance, and covariance\n",
        "\n",
        "Let $\\mathbf{y}=[Y_1,Y_2,\\dots,Y_n]$ be an $n\\times 1$ random vector.\n",
        "\n",
        "The mean of a random vector is the vector containing the means of the random variables in the vector.\n",
        "\n",
        "The mean of $\\mathbf{y}$ is defined as $$\n",
        "E(\\mathbf{y})=\\begin{bmatrix}E(Y_1)\\\\E(Y_2)\\\\\\vdots\\\\E(Y_n)\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "The variance of a random vector isnâ€™t a number or a vector of numbers. Instead, it is the matrix of covariances of all pairs of random variables in the random vector.\n",
        "\n",
        "The variance matrix of $\\mathbf{y}$ is defined as $$\n",
        "\\begin{aligned}\n",
        "\\mathrm{var}(\\mathbf{y}) &= E\\Bigl[(\\mathbf{y} - E(\\mathbf{y}))(\\mathbf{y} - E(\\mathbf{y}))^T\\Bigr]\\\\\n",
        "&= \\begin{bmatrix}\\mathrm{cov}(Y_1, Y_1) & \\mathrm{cov}(Y_1,Y_2) &\\dots &\\mathrm{cov}(Y_1,Y_n)\\\\\\mathrm{cov}(Y_2,Y_1 )&\\mathrm{cov}(Y_2, Y_2)&\\dots&\\mathrm{cov}(Y_2,Y_n)\\\\\\vdots&\\vdots&\\vdots&\\vdots\\\\\n",
        "\\mathrm{cov}(Y_n,Y_1)&\\mathrm{cov}(Y_n,Y_2)&\\dots&\\mathrm{cov}(Y_n, Y_n)\\end{bmatrix}.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "The variance matrix of $\\mathbf{y}$ can also be computed as $$\n",
        "\\mathrm{var}(\\mathbf{y}) = E(\\mathbf{y}\\mathbf{y}^T)-E(\\mathbf{y})E(\\mathbf{y})^T.\n",
        "$$\n",
        "\n",
        "Also, noting that $\\mathrm{cov}(Y, Y) = \\mathrm{var}(Y)$ for a random variable $Y$, we can write the variance matrix of $\\mathbf{y}$ as $$\n",
        "\\begin{aligned}\n",
        "\\mathrm{var}(\\mathbf{y}) &= \\begin{bmatrix}\\mathrm{var}(Y_1) & \\mathrm{cov}(Y_1,Y_2) &\\dots &\\mathrm{cov}(Y_1,Y_n)\\\\\n",
        "\\mathrm{cov}(Y_2,Y_1 )&\\mathrm{var}(Y_2) &\\dots& \\mathrm{cov}(Y_2,Y_n) \\\\\n",
        "\\vdots&\\vdots&\\ddots&\\vdots\\\\\n",
        "\\mathrm{cov}(Y_n,Y_1)&\\mathrm{cov}(Y_n,Y_2)&\\dots&\\mathrm{var}(Y_n)\\end{bmatrix}.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "The variance matrix of $\\mathbf{y}$ is also called the **covariance matrix** or **variance-covariance matrix** of $\\mathbf{y}$.\n",
        "\n",
        "Let $\\mathbf{x} = [X_1, X_2, \\ldots, X_n]$ be an $n\\times 1$ random vector.\n",
        "\n",
        "The covariance matrix between $\\mathbf{x}$ and $\\mathbf{y}$ is defined as $$\n",
        "\\begin{align}\n",
        "\\mathrm{cov}(\\mathbf{x}, \\mathbf{y}) &= E\\bigl[(\\mathbf{x} - E(\\mathbf{x}))(\\mathbf{y}  - E(\\mathbf{y})^T\\bigr]\\\\\n",
        "&=\n",
        "\\begin{bmatrix}\n",
        "\\mathrm{cov}(X_1, Y_1) & \\mathrm{cov}(X_1,Y_2) &\\dots &\\mathrm{cov}(X_1,Y_n) \\\\\n",
        "\\mathrm{cov}(X_2,Y_1 )&\\mathrm{cov}(X_2, Y_2) &\\dots& \\mathrm{cov}(X_2,Y_n) \\\\\n",
        "\\vdots&\\vdots&\\dots&\\vdots\\\\\n",
        "\\mathrm{cov}(X_n,Y_1)&\\mathrm{cov}(X_n,Y_2)&\\dots&\\mathrm{cov}(X_n, Y_n)\n",
        "\\end{bmatrix}.\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "The covariance matrix between $\\mathbf{x}$ and $\\mathbf{y}$ may also be computed as $$\n",
        "\\mathrm{cov}(\\mathbf{x}, \\mathbf{y}) = E(\\mathbf{x}\\mathbf{y}^T) - E(\\mathbf{x}) E(\\mathbf{y})^T.\n",
        "$$\n",
        "\n",
        "Note: $\\mathrm{var}(\\mathbf{y})=\\mathrm{cov}(\\mathbf{y}, \\mathbf{y})$.\n",
        "\n",
        "## Properties of transformations of random vectors\n",
        "\n",
        "Define:\n",
        "\n",
        "-   $\\mathbf{a}$ to be an $n\\times 1$ vector of real numbers.\n",
        "-   $\\mathbf{A}$ to be an $m\\times n$ matrix of real numbers.\n",
        "-   $\\mathbf{x}=[X_1,X_2,\\ldots,X_n]$ to be an $n\\times 1$ random vector.\n",
        "-   $\\mathbf{y}=[Y_1,Y_2,\\ldots,Y_n]$ to be an $n\\times 1$ random vector.\n",
        "-   $\\mathbf{z}=[Z_1,Z_2,\\ldots,Z_n]$ to be an $n\\times 1$ random vector.\n",
        "-   $0_{m\\times n}$ to be an $m\\times n$ matrix of zeros.\n",
        "\n",
        "Then:\n",
        "\n",
        "-   $E(\\mathbf{a}) = \\mathbf{a}$.\n",
        "-   $E(\\mathbf{A}\\mathbf{y})=\\mathbf{A}E(\\mathbf{y})$.\n",
        "-   $E(\\mathbf{y}\\mathbf{A}^T )=E(\\mathbf{y}) \\mathbf{A}^T$.\n",
        "-   $E(\\mathbf{x}+\\mathbf{y})=E(\\mathbf{x})+E(\\mathbf{y})$.\n",
        "-   $\\mathrm{var}(\\mathbf{A}\\mathbf{y})=\\mathbf{A}\\mathrm{var}(\\mathbf{y}) \\mathbf{A}^T$.\n",
        "-   $\\mathrm{cov}(\\mathbf{x}+\\mathbf{y},\\mathbf{z})=\\mathrm{cov}(\\mathbf{x},\\mathbf{z})+\\mathrm{cov}(\\mathbf{y},\\mathbf{z})$.\n",
        "-   $\\mathrm{cov}(\\mathbf{x},\\mathbf{y}+\\mathbf{z})=\\mathrm{cov}(\\mathbf{x},\\mathbf{y})+\\mathrm{cov}(\\mathbf{x},\\mathbf{z})$.\n",
        "-   $\\mathrm{cov}(\\mathbf{A}\\mathbf{x},\\mathbf{y})=\\mathbf{A}\\ \\mathrm{cov}(\\mathbf{x},\\mathbf{y})$.\n",
        "-   $\\mathrm{cov}(\\mathbf{x},\\mathbf{A}\\mathbf{y})=\\mathrm{cov}(\\mathbf{x},\\mathbf{y}) \\mathbf{A}^T$.\n",
        "-   $\\mathrm{var}(\\mathbf{a})= 0_{n\\times n}$.\n",
        "-   $\\mathrm{cov}(\\mathbf{a},\\mathbf{y})=0_{n\\times n}$.\n",
        "-   $\\mathrm{var}(\\mathbf{a}+\\mathbf{y})=\\mathrm{var}(\\mathbf{y})$.\n",
        "\n",
        "## Example (Continuous bivariate distribution continued)\n",
        "\n",
        "We will answer **Q7** of the hydration example from the Multivariate Distributions Appendix using random vectors.\n",
        "\n",
        "We have:\n",
        "\n",
        "-   A $2\\times 1$ random vector $\\mathbf{z}=[X, Y]$.\n",
        "-   The mean of $\\mathbf{z}$ is $E(\\mathbf{z})=[2/5, 4/5]$.\n",
        "-   The variance matrix of $\\mathbf{z}$ is $$\n",
        "    \\mathrm{var}(\\mathbf{z})=\n",
        "    \\begin{bmatrix}\n",
        "    14/225 & 1/75 \\\\\n",
        "    1/75 & 2/75\n",
        "    \\end{bmatrix}.\n",
        "    $$\n",
        "\n",
        "Determine $E(Y-X)$ and $\\mathrm{var}(Y-X)$.\n",
        "\n",
        "Define $\\mathbf{A}=[-1, 1]^T$ (the ROW vector with 1 and -1). Then, $$\n",
        "\\mathbf{Az}=\\begin{bmatrix}-1 & 1\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "X\\\\\n",
        "Y\n",
        "\\end{bmatrix}\n",
        "=Y-X\n",
        "$$\n",
        "\n",
        "and\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "E(Y-X)&=E(\\mathbf{Az})\\\\\n",
        "&=\\begin{bmatrix}-1 & 1\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "2/5\\\\\n",
        "4/5\n",
        "\\end{bmatrix}\\\\\n",
        "&=-2/5+4/5\\\\&=2/5.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Additionally,\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "& \\mathrm{var}(Y-X) \\\\\n",
        "&=\\mathrm{var}(\\mathbf{Az}) \\\\\n",
        "&=\\mathbf{A}\\mathrm{var}(\\mathbf{z})\\mathbf{A}^T \\\\\n",
        "&=\n",
        "\\begin{bmatrix}\n",
        "-1 & 1\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "14/225 & 1/75 \\\\\n",
        "1/75 & 2/75\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "-1 \\\\ 1\n",
        "\\end{bmatrix} \\\\\n",
        "&= \\begin{bmatrix}\n",
        "-14/225+1/75 & -1/75+2/75\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "-1 \\\\ 1\n",
        "\\end{bmatrix} \\\\\n",
        "&= 14/225 - 1/75 -1/75 + 2/75 \\\\\n",
        "&=14/225.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "## Multivariate normal (Gaussian) distribution\n",
        "\n",
        "The random vector $\\mathbf{y}=[Y_1,\\dots,Y_n]$ has a multivariate normal distribution with mean $E(\\mathbf{y})=\\boldsymbol{\\mu}$ (an $n\\times 1$ vector) and covariance matrix $\\mathrm{var}(\\mathbf{y})=\\boldsymbol{\\Sigma}$ (an $n\\times n$ matrix) if its joint pdf is, $$\n",
        "f(\\mathbf{y})=\\frac{1}{(2\\pi)^{n/2} |\\boldsymbol{\\Sigma}|^{1/2} }  \\exp\\left(-\\frac{1}{2} (\\mathbf{y}-\\boldsymbol{\\mu})^T \\boldsymbol{\\Sigma}^{-1} (\\mathbf{y}-\\boldsymbol{\\mu})\\right),\n",
        "$$\n",
        "\n",
        "where $|\\boldsymbol{\\Sigma}|$ is the determinant of $\\boldsymbol{\\Sigma}$. Note that $\\boldsymbol{\\Sigma}$ must be symmetric and positive definite.\n",
        "\n",
        "We denote the distribution of $\\mathbf{y}$ as $$\n",
        "\\mathbf{y}\\sim \\mathsf{N}(\\boldsymbol{\\mu},\\boldsymbol{\\Sigma}).\n",
        "$$\n",
        "\n",
        "## Linear transformation of a multivariate normal random vector\n",
        "\n",
        "Assume the following:\n",
        "\n",
        "-   $\\mathbf{y}$ is an $n\\times 1$ random vector and $\\mathbf{y}\\sim \\mathsf{N}(\\boldsymbol{\\mu},\\boldsymbol{\\Sigma}).$\n",
        "-   $\\mathbf{a}$ is an $m\\times 1$ vector of real numbers.\n",
        "-   $\\mathbf{A}$ is an $m\\times n$ matrix of real numbers.\n",
        "\n",
        "A linear transformation of a multivariate normal random vector of the form $\\mathbf{a}+\\mathbf{A}\\mathbf{y}$ is also a multivariate normal random vector.\n",
        "\n",
        "-   Note: the result could collapse to a single random variable if $\\mathbf{A}$ is a $1\\times n$ vector.\n",
        "\n",
        "**Application**: Suppose that $\\mathbf{y}\\sim \\mathsf{N}(\\boldsymbol{\\mu},\\boldsymbol{\\Sigma})$. For an $m\\times n$ matrix of constants $\\mathbf{A}$, $\\mathbf{A}\\mathbf{y}\\sim \\mathsf{N}(\\mathbf{A}\\boldsymbol{\\mu},\\mathbf{A}\\boldsymbol{\\Sigma} \\mathbf{A}^T)$.\n",
        "\n",
        "The most common estimators used in linear regression are linear combinations of a (typically) multivariate normal random vectors, meaning that many of the estimators also have a (multivariate) normal distribution.\n",
        "\n",
        "## Example (OLS matrix form)\n",
        "\n",
        "Ordinary least squares regression is a method for fitting a linear regression model to data.\n",
        "\n",
        "Suppose that we observed variables $X_1, X_2, X_3, \\ldots, X_{p-1}, Y$ for each of $n$ subjects from some population.\n",
        "\n",
        "-   $X_{i,j}$ denotes the value of $X_j$ for observation $i$.\n",
        "-   $Y_i$ denotes the value of $Y$ for observation $i$.\n",
        "\n",
        "In general, we want to use $X_1, \\ldots, X_{p-1}$ to predict the value of $Y$.\n",
        "\n",
        "Define $\\mathbf{X}$ to be a full-rank $n\\times p$ matrix as $$\n",
        "\\mathbf{X} =\n",
        "\\begin{bmatrix}\n",
        "1 & X_{1,1} & X_{1,2} & \\cdots & X_{1,p-1} \\\\\n",
        "1 & X_{2,1} & X_{2,2} & \\cdots & X_{2,p-1} \\\\\n",
        "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
        "1 & X_{n,1} & X_{n,2} & \\cdots & X_{n,p-1}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Define $\\mathbf{y}$ to be the $n\\times 1$ random vector of responses as $\\mathbf{y}=[Y_1, Y_2, \\ldots,Y_n]$.\n",
        "\n",
        "We assume that, $$\n",
        "\\mathbf{y}\\sim \\mathsf{N}(\\mathbf{X}\\boldsymbol{\\beta}, \\sigma^2 \\mathbf{I}_{n\\times n}).\n",
        "$$\n",
        "\n",
        "-   $\\boldsymbol{\\beta}=[\\beta_0,\\beta_1,\\ldots,\\beta_{p-1}]$ is a $p\\times 1$ vector of real numbers.\n",
        "\n",
        "The matrix $\\mathbf{H}=\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T$ projects $\\mathbf{y}$ into the space spanned by the vectors in $\\mathbf{X}$.\n",
        "\n",
        "Determine the distribution of $\\mathbf{Hy}$.\n",
        "\n",
        "Notice that $$\n",
        "\\begin{aligned}\n",
        "E(\\mathbf{Hy}) &= \\mathbf{H}E(\\mathbf{y}) \\\\  &=\\mathbf{HX}\\boldsymbol{\\beta}\\\\\n",
        "&=\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta} \\\\\n",
        "&=\\mathbf{X}\\mathbf{I}_{p\\times p}\\boldsymbol{\\beta} \\\\\n",
        "&=\\mathbf{X}\\boldsymbol{\\beta}.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Additionally, $$\n",
        "\\begin{aligned}\n",
        "\\mathrm{var}(\\mathbf{Hy}) &= \\mathbf{H}\\mathrm{var}(\\mathbf{y})\\mathbf{H}^T \\\\\n",
        "&=\\mathbf{H}\\sigma^2 \\mathbf{I}_{n\\times n}\\mathbf{\\mathbf{H^T}} \\\\\n",
        "&= \\sigma^2 \\mathbf{H}\\mathbf{H}^T\\\\\n",
        "&=\\sigma^2 \\mathbf{H}.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Lastly, since $\\mathbf{Hy}$ is a linear transformation of a multivariate normal random vector, it also have a multivariate normal distribution.\n",
        "\n",
        "We combine these facts together to see that  \n",
        "$$\n",
        "\\mathbf{Hy}\\sim \\mathsf{N}(\\mathbf{H}\\boldsymbol{\\beta}, \\sigma^2 \\mathbf{H}).\n",
        "$$"
      ],
      "id": "40e080eb-da46-472d-8a84-e488f69cdee7"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "ir",
      "display_name": "R",
      "language": "R"
    }
  }
}