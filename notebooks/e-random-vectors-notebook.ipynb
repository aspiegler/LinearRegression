{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Appendix E - Random Vectors\n",
        "\n",
        "Joshua French\n",
        "\n",
        "To open this information in an interactive Colab notebook, click or scan the QR code below.\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/jfrench/LinearRegression/blob/master/notebooks/e-random-vectors-notebook.ipynb\"> <img src=\"https://raw.githubusercontent.com/jfrench/LinearRegression/3053cf06d8f1cbed7df57ee3a2c7816729f8d12a/images/qr-mult-dists-and-random-vectors.svg\"> </a>\n",
        "\n",
        "# Random vectors\n",
        "\n",
        "## Definition\n",
        "\n",
        "A **random vector** is a vector of random variables. A random vector is assumed to be a column vector unless otherwise specified.\n",
        "\n",
        "Additionally, a **random matrix** is a matrix of random variables.\n",
        "\n",
        "## Mean, variance, and covariance\n",
        "\n",
        "Let $\\mathbf{y}=[Y_1,Y_2,\\dots,Y_n]$ be an $n\\times 1$ random column vector.\n",
        "\n",
        "The mean of a random column vector is the column vector containing the means of the random variables in the vector. More specifically, the mean of $\\mathbf{y}$ is defined as\n",
        "\n",
        "$$\n",
        "E(\\mathbf{y})=\\begin{bmatrix}E(Y_1)\\\\E(Y_2)\\\\\\vdots\\\\E(Y_n)\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "The variance of a random column vector isnâ€™t a number. Instead, it is the matrix of covariances of all pairs of random variables in the random vector. The variance of $\\mathbf{y}$ is\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\mathrm{var}(\\mathbf{y}) &= E(\\mathbf{y}\\mathbf{y}^T )-E(\\mathbf{y})E(\\mathbf{y})^T\\\\\n",
        "&= \\begin{bmatrix}\\mathrm{var}(Y_1) & \\mathrm{cov}(Y_1,Y_2) &\\dots &\\mathrm{cov}(Y_1,Y_n)\\\\\\mathrm{cov}(Y_2,Y_1 )&\\mathrm{var}(Y_2)&\\dots&\\mathrm{cov}(Y_2,Y_n)\\\\\\vdots&\\vdots&\\vdots&\\vdots\\\\\n",
        "\\mathrm{cov}(Y_n,Y_1)&\\mathrm{cov}(Y_n,Y_2)&\\dots&\\mathrm{var}(Y_n)\\end{bmatrix}.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Alternatively, the variance of $\\mathbf{y}$ is called the **covariance matrix** of $\\mathbf{y}$ or the **variance-covariance matrix** of $\\mathbf{y}$.\n",
        "\n",
        "*Note:* $\\mathrm{var}(\\mathbf{y})=\\mathrm{cov}(\\mathbf{y}, \\mathbf{y})$.\n",
        "\n",
        "Let $\\mathbf{x} = [X_1, X_2, \\ldots, X_n]$ be an $n\\times 1$ random vector.\n",
        "\n",
        "The covariance matrix between $\\mathbf{x}$ and $\\mathbf{y}$ is defined as\n",
        "\n",
        "$$\n",
        "\\mathrm{cov}(\\mathbf{x}, \\mathbf{y}) = E(\\mathbf{x}\\mathbf{y}^T) - E(\\mathbf{x}) E(\\mathbf{y})^T.\n",
        "$$\n",
        "\n",
        "## Properties of transformations of random vectors\n",
        "\n",
        "Define:\n",
        "\n",
        "-   $\\mathbf{a}$ to be an $m\\times 1$ vector of real numbers.\n",
        "-   $\\mathbf{A}$ to be an $m\\times n$ matrix of real numbers.\n",
        "-   $\\mathbf{x}=[X_1,X_2,\\ldots,X_n]$ to be an $n\\times 1$ random vector.\n",
        "-   $\\mathbf{y}=[Y_1,Y_2,\\ldots,Y_n]$ to be an $n\\times 1$ random vector.\n",
        "-   $\\mathbf{z}=[Z_1,Z_2,\\ldots,Z_n]$ to be an $n\\times 1$ random vector.\n",
        "-   $0_{m\\times n}$ to be an $m\\times n$ matrix of zeros.\n",
        "\n",
        "Then:\n",
        "\n",
        "-   $E(\\mathbf{A}\\mathbf{y})=\\mathbf{A}E(\\mathbf{y})$.\n",
        "-   $E(\\mathbf{y}\\mathbf{A}^T )=E(\\mathbf{y}) \\mathbf{A}^T$.\n",
        "-   $E(\\mathbf{x}+\\mathbf{y})=E(\\mathbf{x})+E(\\mathbf{y})$.\n",
        "-   $\\mathrm{var}(\\mathbf{A}\\mathbf{y})=\\mathbf{A}\\mathrm{var}(\\mathbf{y}) \\mathbf{A}^T$.\n",
        "-   $\\mathrm{cov}(\\mathbf{x}+\\mathbf{y},\\mathbf{z})=\\mathrm{cov}(\\mathbf{x},\\mathbf{z})+\\mathrm{cov}(\\mathbf{y},\\mathbf{z})$.\n",
        "-   $\\mathrm{cov}(\\mathbf{x},\\mathbf{y}+\\mathbf{z})=\\mathrm{cov}(\\mathbf{x},\\mathbf{y})+\\mathrm{cov}(\\mathbf{x},\\mathbf{z})$.\n",
        "-   $\\mathrm{cov}(\\mathbf{A}\\mathbf{x},\\mathbf{y})=\\mathbf{A}\\ \\mathrm{cov}(\\mathbf{x},\\mathbf{y})$.\n",
        "-   $\\mathrm{cov}(\\mathbf{x},\\mathbf{A}\\mathbf{y})=\\mathrm{cov}(\\mathbf{x},\\mathbf{y}) \\mathbf{A}^T$.\n",
        "-   $\\mathrm{var}(\\mathbf{a})= 0_{n\\times n}$.\n",
        "-   $\\mathrm{cov}(\\mathbf{a},\\mathbf{y})=0_{n\\times n}$.\n",
        "-   $\\mathrm{var}(\\mathbf{a}+\\mathbf{y})=\\mathrm{var}(\\mathbf{y})$.\n",
        "\n",
        "## Example (Continuous bivariate distribution continued)\n",
        "\n",
        "Using the definitions we introduced, we want to answer **Q7** of the hydration example. Summarizing only the essential details, we have a random column vector $\\mathbf{z}=[X, Y]$ with mean $E(\\mathbf{z})=[2/5, 4/5]$ and covariance matrix\n",
        "\n",
        "$$\n",
        "\\mathrm{var}(\\mathbf{z})=\n",
        "\\begin{bmatrix}\n",
        "14/225 & 1/75 \\\\\n",
        "1/75 & 2/75\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Determine $E(Y-X)$ and $\\mathrm{var}(Y-X)$.\n",
        "\n",
        "Define $\\mathbf{A}=[-1, 1]^T$ (the ROW vector with 1 and -1). Then, $$\n",
        "\\mathbf{Az}=\\begin{bmatrix}-1 & 1\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "X\\\\\n",
        "Y\n",
        "\\end{bmatrix}\n",
        "=Y-X\n",
        "$$\n",
        "\n",
        "and\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "E(Y-X)&=E(\\mathbf{Az})\\\\\n",
        "&=\\begin{bmatrix}-1 & 1\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "2/5\\\\\n",
        "4/5\n",
        "\\end{bmatrix}\\\\\n",
        "&=-2/5+4/5\\\\&=2/5.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Additionally,\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "& \\mathrm{var}(Y-X) \\\\\n",
        "&=\\mathrm{var}(\\mathbf{Az}) \\\\\n",
        "&=\\mathbf{A}\\mathrm{var}(\\mathbf{z})\\mathbf{A}^T \\\\\n",
        "&=\n",
        "\\begin{bmatrix}\n",
        "-1 & 1\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "14/225 & 1/75 \\\\\n",
        "1/75 & 2/75\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "-1 \\\\ 1\n",
        "\\end{bmatrix} \\\\\n",
        "&= \\begin{bmatrix}\n",
        "-14/225+1/75 & -1/75+2/75\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "-1 \\\\ 1\n",
        "\\end{bmatrix} \\\\\n",
        "&= 14/225 + 2/75 - 2(1/75) \\\\\n",
        "&=14/225.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "## Linear transformation of a multivariate normal random vector\n",
        "\n",
        "Assume the following:\n",
        "\n",
        "-   The random vector $\\mathbf{y}\\sim \\mathsf{N}(\\boldsymbol{\\mu},\\boldsymbol{\\Sigma}).$\n",
        "-   $\\mathbf{a}$ is an $m\\times 1$ column vector of real numbers.\n",
        "-   $\\mathbf{A}$ is an $m\\times n$ matrix of real numbers.\n",
        "\n",
        "A linear transformation of a multivariate normal random vector of the form $\\mathbf{a}+\\mathbf{A}\\mathbf{y}$ is also multivariate normal random vector.\n",
        "\n",
        "-   Note: the result could collapse to a single random variable if $\\mathbf{A}$ is a $1\\times n$ vector).\n",
        "\n",
        "**Application**: Suppose that $\\mathbf{y}\\sim \\mathsf{N}(\\boldsymbol{\\mu},\\boldsymbol{\\Sigma})$. For an $m\\times n$ matrix of constants $\\mathbf{A}$, $\\mathbf{A}\\mathbf{y}\\sim \\mathsf{N}(\\mathbf{A}\\boldsymbol{\\mu},\\mathbf{A}\\boldsymbol{\\Sigma} \\mathbf{A}^T)$.\n",
        "\n",
        "The most common estimators used in linear regression are linear combinations of a (typically) multivariate normal random vectors, meaning that many of the estimators also have a (multivariate) normal distribution.\n",
        "\n",
        "## Example (OLS matrix form)\n",
        "\n",
        "Ordinary least squares regression is a method for fitting a linear regression model to data. Suppose that we have observed variables $X_1, X_2, X_3, \\ldots, X_{p-1}, Y$ for each of $n$ subjects from some population, with $X_{i,j}$ denoting the value of $X_j$ for observation $i$ and $Y_i$ denoting the value of $Y$ for observation $i$. In general, we want to use $X_1, \\ldots, X_{p-1}$ to predict the value of $Y$. Let, $$\n",
        "\\mathbf{X} =\n",
        "\\begin{bmatrix}\n",
        "1 & X_{1,1} & X_{1,2} & \\cdots & X_{1,p-1} \\\\\n",
        "1 & X_{2,1} & X_{2,2} & \\cdots & X_{2,p-1} \\\\\n",
        "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
        "1 & X_{n,1} & X_{n,2} & \\cdots & X_{n,p-1}\n",
        "\\end{bmatrix}\n",
        "$$ be a full-rank matrix of size $n\\times p$ and $$\n",
        "\\mathbf{y}=[Y_1, Y_2, \\ldots,Y_n],\n",
        "$$ be an $n\\times 1$ column vector of responses.\n",
        "\n",
        "We assume that, $$\n",
        "\\mathbf{y}\\sim \\mathsf{N}(\\mathbf{X}\\boldsymbol{\\beta}, \\sigma^2 \\mathbf{I}_{n\\times n}).\n",
        "$$\n",
        "\n",
        "-   $\\boldsymbol{\\beta}=[\\beta_0,\\beta_1,\\ldots,\\beta_{p-1}]$ is a $p$-dimensional column vector of constants.\n",
        "\n",
        "The matrix $\\mathbf{H}=\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T$ projects $\\mathbf{y}$ into the space spanned by the vectors in $\\mathbf{X}$.\n",
        "\n",
        "Determine the distribution of $\\mathbf{Hy}.$\n",
        "\n",
        "$$\n",
        "\\mathbf{Hy}\\sim \\mathsf{N}(\\mathbf{HX}\\boldsymbol{\\beta}, \\sigma^2 \\mathbf{H}\\mathbf{I}_{n\\times n}\\mathbf{H}^T).\n",
        "$$\n",
        "\n",
        "Notice that $$\n",
        "\\begin{aligned}\n",
        "\\mathbf{HX}\\boldsymbol{\\beta}&=\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta} \\\\\n",
        "&=\\mathbf{X}\\mathbf{I}_{p\\times p}\\boldsymbol{\\beta} \\\\\n",
        "&=\\mathbf{X}\\boldsymbol{\\beta}.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Additionally, $$\n",
        "\\begin{aligned}\n",
        "\\mathbf{H}\\sigma^2 \\mathbf{I}_{n\\times n} \\mathbf{\\mathbf{H^T}} &= \\sigma^2 \\mathbf{H}\\mathbf{H}^T\\\\\n",
        "&=\\sigma^2 \\mathbf{H}.\n",
        "\\end{aligned}\n",
        "$$"
      ],
      "id": "92cf8eae-9a79-4f10-a47b-f76df0d93c18"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "ir",
      "display_name": "R",
      "language": "R"
    }
  }
}