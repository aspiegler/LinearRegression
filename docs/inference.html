<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Linear model inference and prediction | A Progressive Introduction to Linear Models</title>
  <meta name="description" content="A collection of material that progressively introduces how to fit and use linear models." />
  <meta name="generator" content="bookdown 0.41 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Linear model inference and prediction | A Progressive Introduction to Linear Models" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="A collection of material that progressively introduces how to fit and use linear models." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Linear model inference and prediction | A Progressive Introduction to Linear Models" />
  
  <meta name="twitter:description" content="A collection of material that progressively introduces how to fit and use linear models." />
  

<meta name="author" content="Joshua French" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="linear-model-theory.html"/>
<link rel="next" href="overview-of-matrix-facts.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.10.4/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.1/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.11.1/plotly-latest.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Progressive Introduction to Linear Models</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preliminaries</a></li>
<li class="chapter" data-level="1" data-path="r-foundations.html"><a href="r-foundations.html"><i class="fa fa-check"></i><b>1</b> R Foundations</a>
<ul>
<li class="chapter" data-level="1.1" data-path="r-foundations.html"><a href="r-foundations.html#setting-up-r-and-rstudio-desktop"><i class="fa fa-check"></i><b>1.1</b> Setting up R and RStudio Desktop</a></li>
<li class="chapter" data-level="1.2" data-path="r-foundations.html"><a href="r-foundations.html#running-code-scripts-and-comments"><i class="fa fa-check"></i><b>1.2</b> Running code, scripts, and comments</a></li>
<li class="chapter" data-level="1.3" data-path="r-foundations.html"><a href="r-foundations.html#assignment"><i class="fa fa-check"></i><b>1.3</b> Assignment</a></li>
<li class="chapter" data-level="1.4" data-path="r-foundations.html"><a href="r-foundations.html#functions"><i class="fa fa-check"></i><b>1.4</b> Functions</a></li>
<li class="chapter" data-level="1.5" data-path="r-foundations.html"><a href="r-foundations.html#packages"><i class="fa fa-check"></i><b>1.5</b> Packages</a></li>
<li class="chapter" data-level="1.6" data-path="r-foundations.html"><a href="r-foundations.html#getting-help"><i class="fa fa-check"></i><b>1.6</b> Getting help</a></li>
<li class="chapter" data-level="1.7" data-path="r-foundations.html"><a href="r-foundations.html#data-types-and-structures"><i class="fa fa-check"></i><b>1.7</b> Data types and structures</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="r-foundations.html"><a href="r-foundations.html#basic-data-types"><i class="fa fa-check"></i><b>1.7.1</b> Basic data types</a></li>
<li class="chapter" data-level="1.7.2" data-path="r-foundations.html"><a href="r-foundations.html#other-important-object-types"><i class="fa fa-check"></i><b>1.7.2</b> Other important object types</a></li>
<li class="chapter" data-level="1.7.3" data-path="r-foundations.html"><a href="r-foundations.html#data-structures"><i class="fa fa-check"></i><b>1.7.3</b> Data structures</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="r-foundations.html"><a href="r-foundations.html#vectors"><i class="fa fa-check"></i><b>1.8</b> Vectors</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="r-foundations.html"><a href="r-foundations.html#creation"><i class="fa fa-check"></i><b>1.8.1</b> Creation</a></li>
<li class="chapter" data-level="1.8.2" data-path="r-foundations.html"><a href="r-foundations.html#categorical-vectors"><i class="fa fa-check"></i><b>1.8.2</b> Categorical vectors</a></li>
<li class="chapter" data-level="1.8.3" data-path="r-foundations.html"><a href="r-foundations.html#extracting-parts-of-a-vector"><i class="fa fa-check"></i><b>1.8.3</b> Extracting parts of a vector</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="r-foundations.html"><a href="r-foundations.html#helpful-functions"><i class="fa fa-check"></i><b>1.9</b> Helpful functions</a>
<ul>
<li class="chapter" data-level="1.9.1" data-path="r-foundations.html"><a href="r-foundations.html#general-functions"><i class="fa fa-check"></i><b>1.9.1</b> General functions</a></li>
<li class="chapter" data-level="1.9.2" data-path="r-foundations.html"><a href="r-foundations.html#functions-related-to-statistical-distributions"><i class="fa fa-check"></i><b>1.9.2</b> Functions related to statistical distributions</a></li>
</ul></li>
<li class="chapter" data-level="1.10" data-path="r-foundations.html"><a href="r-foundations.html#data-frames"><i class="fa fa-check"></i><b>1.10</b> Data Frames</a>
<ul>
<li class="chapter" data-level="1.10.1" data-path="r-foundations.html"><a href="r-foundations.html#direct-creation"><i class="fa fa-check"></i><b>1.10.1</b> Direct creation</a></li>
<li class="chapter" data-level="1.10.2" data-path="r-foundations.html"><a href="r-foundations.html#importing-data"><i class="fa fa-check"></i><b>1.10.2</b> Importing Data</a></li>
<li class="chapter" data-level="1.10.3" data-path="r-foundations.html"><a href="r-foundations.html#extracting-parts-of-a-data-frame"><i class="fa fa-check"></i><b>1.10.3</b> Extracting parts of a data frame</a></li>
</ul></li>
<li class="chapter" data-level="1.11" data-path="r-foundations.html"><a href="r-foundations.html#using-the-pipe-operator"><i class="fa fa-check"></i><b>1.11</b> Using the pipe operator</a></li>
<li class="chapter" data-level="1.12" data-path="r-foundations.html"><a href="r-foundations.html#dealing-with-common-problems"><i class="fa fa-check"></i><b>1.12</b> Dealing with common problems</a></li>
<li class="chapter" data-level="1.13" data-path="r-foundations.html"><a href="r-foundations.html#ecosystem-debate"><i class="fa fa-check"></i><b>1.13</b> Ecosystem debate</a></li>
<li class="chapter" data-level="1.14" data-path="r-foundations.html"><a href="r-foundations.html#additional-information"><i class="fa fa-check"></i><b>1.14</b> Additional information</a>
<ul>
<li class="chapter" data-level="1.14.1" data-path="r-foundations.html"><a href="r-foundations.html#comparing-assignment-operators"><i class="fa fa-check"></i><b>1.14.1</b> Comparing assignment operators</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="data-cleaning-and-exploration.html"><a href="data-cleaning-and-exploration.html"><i class="fa fa-check"></i><b>2</b> Data cleaning and exploration</a>
<ul>
<li class="chapter" data-level="2.1" data-path="data-cleaning-and-exploration.html"><a href="data-cleaning-and-exploration.html#raw-palmer-penguins-data"><i class="fa fa-check"></i><b>2.1</b> Raw Palmer penguins data</a></li>
<li class="chapter" data-level="2.2" data-path="data-cleaning-and-exploration.html"><a href="data-cleaning-and-exploration.html#initial-data-cleaning"><i class="fa fa-check"></i><b>2.2</b> Initial data cleaning</a></li>
<li class="chapter" data-level="2.3" data-path="data-cleaning-and-exploration.html"><a href="data-cleaning-and-exploration.html#numerical-summarization-of-data"><i class="fa fa-check"></i><b>2.3</b> Numerical summarization of data</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="data-cleaning-and-exploration.html"><a href="data-cleaning-and-exploration.html#numeric-data"><i class="fa fa-check"></i><b>2.3.1</b> Numeric data</a></li>
<li class="chapter" data-level="2.3.2" data-path="data-cleaning-and-exploration.html"><a href="data-cleaning-and-exploration.html#categorical-data"><i class="fa fa-check"></i><b>2.3.2</b> Categorical data</a></li>
<li class="chapter" data-level="2.3.3" data-path="data-cleaning-and-exploration.html"><a href="data-cleaning-and-exploration.html#the-summary-function"><i class="fa fa-check"></i><b>2.3.3</b> The <code>summary</code> function</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="data-cleaning-and-exploration.html"><a href="data-cleaning-and-exploration.html#visual-summaries-of-data"><i class="fa fa-check"></i><b>2.4</b> Visual summaries of data</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="data-cleaning-and-exploration.html"><a href="data-cleaning-and-exploration.html#the-ggplot-recipe"><i class="fa fa-check"></i><b>2.4.1</b> The ggplot recipe</a></li>
<li class="chapter" data-level="2.4.2" data-path="data-cleaning-and-exploration.html"><a href="data-cleaning-and-exploration.html#univariate-plots"><i class="fa fa-check"></i><b>2.4.2</b> Univariate plots</a></li>
<li class="chapter" data-level="2.4.3" data-path="data-cleaning-and-exploration.html"><a href="data-cleaning-and-exploration.html#bivariate-plots"><i class="fa fa-check"></i><b>2.4.3</b> Bivariate plots</a></li>
<li class="chapter" data-level="2.4.4" data-path="data-cleaning-and-exploration.html"><a href="data-cleaning-and-exploration.html#multivariate-plots"><i class="fa fa-check"></i><b>2.4.4</b> Multivariate plots</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="data-cleaning-and-exploration.html"><a href="data-cleaning-and-exploration.html#a-plan-for-data-cleaning-and-exploration"><i class="fa fa-check"></i><b>2.5</b> A plan for data cleaning and exploration</a></li>
<li class="chapter" data-level="2.6" data-path="data-cleaning-and-exploration.html"><a href="data-cleaning-and-exploration.html#final-notes-on-missing-or-erroneous-data"><i class="fa fa-check"></i><b>2.6</b> Final notes on missing or erroneous data</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html"><i class="fa fa-check"></i><b>3</b> Linear model estimation</a>
<ul>
<li class="chapter" data-level="3.1" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#a-simple-motivating-example"><i class="fa fa-check"></i><b>3.1</b> A simple motivating example</a></li>
<li class="chapter" data-level="3.2" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#s-slr-estimation"><i class="fa fa-check"></i><b>3.2</b> Estimation of the simple linear regression model</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#ss:fv-resid-rss"><i class="fa fa-check"></i><b>3.2.1</b> Model definition, fitted values, residuals, and RSS</a></li>
<li class="chapter" data-level="3.2.2" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#ols-estimators-of-the-simple-linear-regression-parameters"><i class="fa fa-check"></i><b>3.2.2</b> OLS estimators of the simple linear regression parameters</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#s:penguins-slr"><i class="fa fa-check"></i><b>3.3</b> Penguins simple linear regression example</a></li>
<li class="chapter" data-level="3.4" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#defining-a-linear-model"><i class="fa fa-check"></i><b>3.4</b> Defining a linear model</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#ss-necessary-components"><i class="fa fa-check"></i><b>3.4.1</b> Necessary components and notation</a></li>
<li class="chapter" data-level="3.4.2" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#standard-definition-of-linear-model"><i class="fa fa-check"></i><b>3.4.2</b> Standard definition of linear model</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#estimation-of-the-multiple-linear-regression-model"><i class="fa fa-check"></i><b>3.5</b> Estimation of the multiple linear regression model</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#using-matrix-notation-to-represent-a-linear-model"><i class="fa fa-check"></i><b>3.5.1</b> Using matrix notation to represent a linear model</a></li>
<li class="chapter" data-level="3.5.2" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#ss:fv-resid-rss-mlr"><i class="fa fa-check"></i><b>3.5.2</b> Residuals, fitted values, and RSS for multiple linear regression</a></li>
<li class="chapter" data-level="3.5.3" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#ols-estimator-of-the-regression-coefficients"><i class="fa fa-check"></i><b>3.5.3</b> OLS estimator of the regression coefficients</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#s:penguins-mlr"><i class="fa fa-check"></i><b>3.6</b> Penguins multiple linear regression example</a></li>
<li class="chapter" data-level="3.7" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#model-types"><i class="fa fa-check"></i><b>3.7</b> Types of linear models</a></li>
<li class="chapter" data-level="3.8" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#categorical-predictors"><i class="fa fa-check"></i><b>3.8</b> Categorical predictors</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#indicator-variables"><i class="fa fa-check"></i><b>3.8.1</b> Indicator variables</a></li>
<li class="chapter" data-level="3.8.2" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#parallel-and-separate-lines-models"><i class="fa fa-check"></i><b>3.8.2</b> Parallel and separate lines models</a></li>
<li class="chapter" data-level="3.8.3" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#extensions"><i class="fa fa-check"></i><b>3.8.3</b> Extensions</a></li>
<li class="chapter" data-level="3.8.4" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#avoiding-an-easy-mistake"><i class="fa fa-check"></i><b>3.8.4</b> Avoiding an easy mistake</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#s:penguins-mlr2"><i class="fa fa-check"></i><b>3.9</b> Penguins example with categorical predictor</a></li>
<li class="chapter" data-level="3.10" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#evaluating-model-fit"><i class="fa fa-check"></i><b>3.10</b> Evaluating model fit</a></li>
<li class="chapter" data-level="3.11" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#summary"><i class="fa fa-check"></i><b>3.11</b> Summary</a>
<ul>
<li class="chapter" data-level="3.11.1" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#ss:term-summary"><i class="fa fa-check"></i><b>3.11.1</b> Summary of terms</a></li>
<li class="chapter" data-level="3.11.2" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#summary-of-functions"><i class="fa fa-check"></i><b>3.11.2</b> Summary of functions</a></li>
</ul></li>
<li class="chapter" data-level="3.12" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#going-deeper"><i class="fa fa-check"></i><b>3.12</b> Going Deeper</a>
<ul>
<li class="chapter" data-level="3.12.1" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#degrees-of-freedom"><i class="fa fa-check"></i><b>3.12.1</b> Degrees of freedom</a></li>
<li class="chapter" data-level="3.12.2" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#slr-derivation"><i class="fa fa-check"></i><b>3.12.2</b> Derivation of the OLS estimators of the simple linear regression model coefficients</a></li>
<li class="chapter" data-level="3.12.3" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#unbiasedness-of-ols-estimators"><i class="fa fa-check"></i><b>3.12.3</b> Unbiasedness of OLS estimators</a></li>
<li class="chapter" data-level="3.12.4" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#manual-calculation-penguins-simple-linear-regression-example"><i class="fa fa-check"></i><b>3.12.4</b> Manual calculation Penguins simple linear regression example</a></li>
<li class="chapter" data-level="3.12.5" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#mlr-derivation"><i class="fa fa-check"></i><b>3.12.5</b> Derivation of the OLS estimator for the multiple linear regression model coefficients</a></li>
<li class="chapter" data-level="3.12.6" data-path="linear-model-estimation.html"><a href="linear-model-estimation.html#manual-calculation-of-penguins-multiple-linear-regression-example"><i class="fa fa-check"></i><b>3.12.6</b> Manual calculation of Penguins multiple linear regression example</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="interp-chapter.html"><a href="interp-chapter.html"><i class="fa fa-check"></i><b>4</b> Interpreting a fitted linear model</a>
<ul>
<li class="chapter" data-level="4.1" data-path="interp-chapter.html"><a href="interp-chapter.html#interpretation-of-coefficients"><i class="fa fa-check"></i><b>4.1</b> Interpretation of coefficients</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="interp-chapter.html"><a href="interp-chapter.html#interpretation-for-simple-linear-regression"><i class="fa fa-check"></i><b>4.1.1</b> Interpretation for simple linear regression</a></li>
<li class="chapter" data-level="4.1.2" data-path="interp-chapter.html"><a href="interp-chapter.html#interp-1st-order-ml"><i class="fa fa-check"></i><b>4.1.2</b> Interpretation for first-order multiple linear regression models</a></li>
<li class="chapter" data-level="4.1.3" data-path="interp-chapter.html"><a href="interp-chapter.html#regressor-roles"><i class="fa fa-check"></i><b>4.1.3</b> Roles of regressor variables</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="interp-chapter.html"><a href="interp-chapter.html#effect-plots"><i class="fa fa-check"></i><b>4.2</b> Effect plots</a></li>
<li class="chapter" data-level="4.3" data-path="interp-chapter.html"><a href="interp-chapter.html#interp-cat-predictor"><i class="fa fa-check"></i><b>4.3</b> Interpretation for categorical predictors</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="interp-chapter.html"><a href="interp-chapter.html#pl-interp"><i class="fa fa-check"></i><b>4.3.1</b> Coefficient interpretation for parallel lines models</a></li>
<li class="chapter" data-level="4.3.2" data-path="interp-chapter.html"><a href="interp-chapter.html#effect-plots-for-fitted-models-with-non-interacting-categorical-predictors"><i class="fa fa-check"></i><b>4.3.2</b> Effect plots for fitted models with non-interacting categorical predictors</a></li>
<li class="chapter" data-level="4.3.3" data-path="interp-chapter.html"><a href="interp-chapter.html#sl-interp"><i class="fa fa-check"></i><b>4.3.3</b> Coefficient interpretation for separate lines models</a></li>
<li class="chapter" data-level="4.3.4" data-path="interp-chapter.html"><a href="interp-chapter.html#effect-plots-for-interacting-categorical-predictors"><i class="fa fa-check"></i><b>4.3.4</b> Effect plots for interacting categorical predictors</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="interp-chapter.html"><a href="interp-chapter.html#added-variable-and-leverage-plots"><i class="fa fa-check"></i><b>4.4</b> Added-variable and leverage plots</a></li>
<li class="chapter" data-level="4.5" data-path="interp-chapter.html"><a href="interp-chapter.html#going-deeper-1"><i class="fa fa-check"></i><b>4.5</b> Going deeper</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="interp-chapter.html"><a href="interp-chapter.html#orthogonality"><i class="fa fa-check"></i><b>4.5.1</b> Orthogonality</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="linear-model-theory.html"><a href="linear-model-theory.html"><i class="fa fa-check"></i><b>5</b> Basic theoretical results for linear models</a>
<ul>
<li class="chapter" data-level="5.1" data-path="linear-model-theory.html"><a href="linear-model-theory.html#standard-assumptions"><i class="fa fa-check"></i><b>5.1</b> Standard assumptions</a></li>
<li class="chapter" data-level="5.2" data-path="linear-model-theory.html"><a href="linear-model-theory.html#summary-of-results"><i class="fa fa-check"></i><b>5.2</b> Summary of results</a></li>
<li class="chapter" data-level="5.3" data-path="linear-model-theory.html"><a href="linear-model-theory.html#results-for-mathbfy"><i class="fa fa-check"></i><b>5.3</b> Results for <span class="math inline">\(\mathbf{y}\)</span></a></li>
<li class="chapter" data-level="5.4" data-path="linear-model-theory.html"><a href="linear-model-theory.html#results-for-hatboldsymbolbeta"><i class="fa fa-check"></i><b>5.4</b> Results for <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span></a></li>
<li class="chapter" data-level="5.5" data-path="linear-model-theory.html"><a href="linear-model-theory.html#results-for-the-residuals"><i class="fa fa-check"></i><b>5.5</b> Results for the residuals</a></li>
<li class="chapter" data-level="5.6" data-path="linear-model-theory.html"><a href="linear-model-theory.html#the-gauss-markov-theorem"><i class="fa fa-check"></i><b>5.6</b> The Gauss-Markov Theorem</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="inference.html"><a href="inference.html"><i class="fa fa-check"></i><b>6</b> Linear model inference and prediction</a>
<ul>
<li class="chapter" data-level="6.1" data-path="inference.html"><a href="inference.html#overview-of-inference-and-prediction"><i class="fa fa-check"></i><b>6.1</b> Overview of inference and prediction</a></li>
<li class="chapter" data-level="6.2" data-path="inference.html"><a href="inference.html#some-relevant-distributions"><i class="fa fa-check"></i><b>6.2</b> Some relevant distributions</a></li>
<li class="chapter" data-level="6.3" data-path="inference.html"><a href="inference.html#properties-betahat"><i class="fa fa-check"></i><b>6.3</b> Assumptions and properties of the OLS estimator</a></li>
<li class="chapter" data-level="6.4" data-path="inference.html"><a href="inference.html#parametric-confidence-intervals-for-regression-coefficients"><i class="fa fa-check"></i><b>6.4</b> Parametric confidence intervals for regression coefficients</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="inference.html"><a href="inference.html#tci"><i class="fa fa-check"></i><b>6.4.1</b> Standard <span class="math inline">\(t\)</span>-based confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="inference.html"><a href="inference.html#mcp"><i class="fa fa-check"></i><b>6.5</b> The multiple comparisons problem</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="inference.html"><a href="inference.html#adjusted-cis-betas"><i class="fa fa-check"></i><b>6.5.1</b> Adjusted confidence intervals for regression coefficients</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="inference.html"><a href="inference.html#prediction-mean-response-versus-new-response"><i class="fa fa-check"></i><b>6.6</b> Prediction: mean response versus new response</a></li>
<li class="chapter" data-level="6.7" data-path="inference.html"><a href="inference.html#parametric-ci-mean-response"><i class="fa fa-check"></i><b>6.7</b> Confidence interval for the mean response</a></li>
<li class="chapter" data-level="6.8" data-path="inference.html"><a href="inference.html#pi-new-response"><i class="fa fa-check"></i><b>6.8</b> Prediction interval for a new response</a></li>
<li class="chapter" data-level="6.9" data-path="inference.html"><a href="inference.html#hypothesis-tests-for-a-single-regression-coefficient"><i class="fa fa-check"></i><b>6.9</b> Hypothesis tests for a single regression coefficient</a></li>
<li class="chapter" data-level="6.10" data-path="inference.html"><a href="inference.html#hypothesis-tests-for-multiple-regression-coefficients"><i class="fa fa-check"></i><b>6.10</b> Hypothesis tests for multiple regression coefficients</a>
<ul>
<li class="chapter" data-level="6.10.1" data-path="inference.html"><a href="inference.html#test-for-a-regression-relationship"><i class="fa fa-check"></i><b>6.10.1</b> Test for a regression relationship</a></li>
<li class="chapter" data-level="6.10.2" data-path="inference.html"><a href="inference.html#a-more-general-f-test"><i class="fa fa-check"></i><b>6.10.2</b> A more general F test</a></li>
</ul></li>
<li class="chapter" data-level="6.11" data-path="inference.html"><a href="inference.html#going-deeper-2"><i class="fa fa-check"></i><b>6.11</b> Going deeper</a>
<ul>
<li class="chapter" data-level="6.11.1" data-path="inference.html"><a href="inference.html#manual-t-cis"><i class="fa fa-check"></i><b>6.11.1</b> Manual calculation of the standard <span class="math inline">\(t\)</span>-based confidence interval for a regression coefficient</a></li>
<li class="chapter" data-level="6.11.2" data-path="inference.html"><a href="inference.html#mean-response-calculations"><i class="fa fa-check"></i><b>6.11.2</b> Details about estimation of the mean response</a></li>
<li class="chapter" data-level="6.11.3" data-path="inference.html"><a href="inference.html#manual-calc-ci-mean-response"><i class="fa fa-check"></i><b>6.11.3</b> Manual calculation of confidence intervals for the mean response</a></li>
<li class="chapter" data-level="6.11.4" data-path="inference.html"><a href="inference.html#new-response-pi-calculations"><i class="fa fa-check"></i><b>6.11.4</b> Details about prediction interval for a new response</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html"><i class="fa fa-check"></i><b>A</b> Overview of matrix facts</a>
<ul>
<li class="chapter" data-level="A.1" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#notation"><i class="fa fa-check"></i><b>A.1</b> Notation</a></li>
<li class="chapter" data-level="A.2" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#basic-mathematical-operations"><i class="fa fa-check"></i><b>A.2</b> Basic mathematical operations</a>
<ul>
<li class="chapter" data-level="A.2.1" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#addition-and-subtraction"><i class="fa fa-check"></i><b>A.2.1</b> Addition and subtraction</a></li>
<li class="chapter" data-level="A.2.2" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#scalar-multiplication"><i class="fa fa-check"></i><b>A.2.2</b> Scalar multiplication</a></li>
<li class="chapter" data-level="A.2.3" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#matrix-multiplication"><i class="fa fa-check"></i><b>A.2.3</b> Matrix multiplication</a></li>
<li class="chapter" data-level="A.2.4" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#transpose"><i class="fa fa-check"></i><b>A.2.4</b> Transpose</a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#basic-mathematical-properties"><i class="fa fa-check"></i><b>A.3</b> Basic mathematical properties</a>
<ul>
<li class="chapter" data-level="A.3.1" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#associative-property"><i class="fa fa-check"></i><b>A.3.1</b> Associative property</a></li>
<li class="chapter" data-level="A.3.2" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#distributive-property"><i class="fa fa-check"></i><b>A.3.2</b> Distributive property</a></li>
<li class="chapter" data-level="A.3.3" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#no-commutative-property"><i class="fa fa-check"></i><b>A.3.3</b> No commutative property</a></li>
<li class="chapter" data-level="A.3.4" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#transpose-related-properties"><i class="fa fa-check"></i><b>A.3.4</b> Transpose-related properties</a></li>
</ul></li>
<li class="chapter" data-level="A.4" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#special-matrices"><i class="fa fa-check"></i><b>A.4</b> Special matrices</a>
<ul>
<li class="chapter" data-level="A.4.1" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#square-matrices"><i class="fa fa-check"></i><b>A.4.1</b> Square matrices</a></li>
<li class="chapter" data-level="A.4.2" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#identity-matrix"><i class="fa fa-check"></i><b>A.4.2</b> Identity matrix</a></li>
<li class="chapter" data-level="A.4.3" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#diagonal-matrices"><i class="fa fa-check"></i><b>A.4.3</b> Diagonal matrices</a></li>
<li class="chapter" data-level="A.4.4" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#symmetric-matrices"><i class="fa fa-check"></i><b>A.4.4</b> Symmetric matrices</a></li>
<li class="chapter" data-level="A.4.5" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#idempotent-matrices"><i class="fa fa-check"></i><b>A.4.5</b> Idempotent matrices</a></li>
<li class="chapter" data-level="A.4.6" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#positive-definite-matrices"><i class="fa fa-check"></i><b>A.4.6</b> Positive definite matrices</a></li>
<li class="chapter" data-level="A.4.7" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#inverse-matrix"><i class="fa fa-check"></i><b>A.4.7</b> Inverse matrix</a></li>
</ul></li>
<li class="chapter" data-level="A.5" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#matrix-derivatives"><i class="fa fa-check"></i><b>A.5</b> Matrix derivatives</a></li>
<li class="chapter" data-level="A.6" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#additional-topics"><i class="fa fa-check"></i><b>A.6</b> Additional topics</a>
<ul>
<li class="chapter" data-level="A.6.1" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#determinant"><i class="fa fa-check"></i><b>A.6.1</b> Determinant</a></li>
<li class="chapter" data-level="A.6.2" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#linearly-independent-vectors"><i class="fa fa-check"></i><b>A.6.2</b> Linearly independent vectors</a></li>
<li class="chapter" data-level="A.6.3" data-path="overview-of-matrix-facts.html"><a href="overview-of-matrix-facts.html#rank"><i class="fa fa-check"></i><b>A.6.3</b> Rank</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="prob-review.html"><a href="prob-review.html"><i class="fa fa-check"></i><b>B</b> Overview of probability, random variables, and random vectors</a>
<ul>
<li class="chapter" data-level="B.1" data-path="prob-review.html"><a href="prob-review.html#probability-basics"><i class="fa fa-check"></i><b>B.1</b> Probability Basics</a></li>
<li class="chapter" data-level="B.2" data-path="prob-review.html"><a href="prob-review.html#random-variables"><i class="fa fa-check"></i><b>B.2</b> Random Variables</a>
<ul>
<li class="chapter" data-level="B.2.1" data-path="prob-review.html"><a href="prob-review.html#discrete-random-variables"><i class="fa fa-check"></i><b>B.2.1</b> Discrete random variables</a></li>
<li class="chapter" data-level="B.2.2" data-path="prob-review.html"><a href="prob-review.html#continuous-random-variables"><i class="fa fa-check"></i><b>B.2.2</b> Continuous random variables</a></li>
<li class="chapter" data-level="B.2.3" data-path="prob-review.html"><a href="prob-review.html#useful-facts-for-transformations-of-random-variables"><i class="fa fa-check"></i><b>B.2.3</b> Useful facts for transformations of random variables</a></li>
</ul></li>
<li class="chapter" data-level="B.3" data-path="prob-review.html"><a href="prob-review.html#multivariate-distributions"><i class="fa fa-check"></i><b>B.3</b> Multivariate distributions</a>
<ul>
<li class="chapter" data-level="B.3.1" data-path="prob-review.html"><a href="prob-review.html#basic-properties"><i class="fa fa-check"></i><b>B.3.1</b> Basic properties</a></li>
<li class="chapter" data-level="B.3.2" data-path="prob-review.html"><a href="prob-review.html#marginal-distributions"><i class="fa fa-check"></i><b>B.3.2</b> Marginal distributions</a></li>
<li class="chapter" data-level="B.3.3" data-path="prob-review.html"><a href="prob-review.html#independence-of-random-variables"><i class="fa fa-check"></i><b>B.3.3</b> Independence of random variables</a></li>
<li class="chapter" data-level="B.3.4" data-path="prob-review.html"><a href="prob-review.html#conditional-distributions"><i class="fa fa-check"></i><b>B.3.4</b> Conditional distributions</a></li>
<li class="chapter" data-level="B.3.5" data-path="prob-review.html"><a href="prob-review.html#covariance"><i class="fa fa-check"></i><b>B.3.5</b> Covariance</a></li>
<li class="chapter" data-level="B.3.6" data-path="prob-review.html"><a href="prob-review.html#useful-facts-for-transformations-of-multiple-random-variables"><i class="fa fa-check"></i><b>B.3.6</b> Useful facts for transformations of multiple random variables</a></li>
<li class="chapter" data-level="B.3.7" data-path="prob-review.html"><a href="prob-review.html#example-binomial"><i class="fa fa-check"></i><b>B.3.7</b> Example (Binomial)</a></li>
<li class="chapter" data-level="B.3.8" data-path="prob-review.html"><a href="prob-review.html#continuous-bivariate-distribution-example"><i class="fa fa-check"></i><b>B.3.8</b> Example (Continuous bivariate distribution)</a></li>
</ul></li>
<li class="chapter" data-level="B.4" data-path="prob-review.html"><a href="prob-review.html#random-vectors"><i class="fa fa-check"></i><b>B.4</b> Random vectors</a>
<ul>
<li class="chapter" data-level="B.4.1" data-path="prob-review.html"><a href="prob-review.html#definition"><i class="fa fa-check"></i><b>B.4.1</b> Definition</a></li>
<li class="chapter" data-level="B.4.2" data-path="prob-review.html"><a href="prob-review.html#mean-variance-and-covariance"><i class="fa fa-check"></i><b>B.4.2</b> Mean, variance, and covariance</a></li>
<li class="chapter" data-level="B.4.3" data-path="prob-review.html"><a href="prob-review.html#properties-of-transformations-of-random-vectors"><i class="fa fa-check"></i><b>B.4.3</b> Properties of transformations of random vectors</a></li>
<li class="chapter" data-level="B.4.4" data-path="prob-review.html"><a href="prob-review.html#example-continuous-bivariate-distribution-continued"><i class="fa fa-check"></i><b>B.4.4</b> Example (Continuous bivariate distribution continued)</a></li>
</ul></li>
<li class="chapter" data-level="B.5" data-path="prob-review.html"><a href="prob-review.html#multivariate-normal-gaussian-distribution"><i class="fa fa-check"></i><b>B.5</b> Multivariate normal (Gaussian) distribution</a>
<ul>
<li class="chapter" data-level="B.5.1" data-path="prob-review.html"><a href="prob-review.html#definition-1"><i class="fa fa-check"></i><b>B.5.1</b> Definition</a></li>
<li class="chapter" data-level="B.5.2" data-path="prob-review.html"><a href="prob-review.html#linear-functions-of-a-multivariate-normal-random-vector"><i class="fa fa-check"></i><b>B.5.2</b> Linear functions of a multivariate normal random vector</a></li>
<li class="chapter" data-level="B.5.3" data-path="prob-review.html"><a href="prob-review.html#example-ols-matrix-form"><i class="fa fa-check"></i><b>B.5.3</b> Example (OLS matrix form)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="C" data-path="est-infer-review.html"><a href="est-infer-review.html"><i class="fa fa-check"></i><b>C</b> Review of Estimation and Inference</a>
<ul>
<li class="chapter" data-level="C.1" data-path="est-infer-review.html"><a href="est-infer-review.html#estimation"><i class="fa fa-check"></i><b>C.1</b> Estimation</a></li>
<li class="chapter" data-level="C.2" data-path="est-infer-review.html"><a href="est-infer-review.html#hypothesis-testing"><i class="fa fa-check"></i><b>C.2</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="C.3" data-path="est-infer-review.html"><a href="est-infer-review.html#confidence-intervals"><i class="fa fa-check"></i><b>C.3</b> Confidence Intervals</a></li>
<li class="chapter" data-level="C.4" data-path="est-infer-review.html"><a href="est-infer-review.html#linking-hypothesis-tests-and-confidence-intervals"><i class="fa fa-check"></i><b>C.4</b> Linking Hypothesis Tests and Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Progressive Introduction to Linear Models</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="inference" class="section level1 hasAnchor" number="6">
<h1><span class="header-section-number">Chapter 6</span> Linear model inference and prediction<a href="inference.html#inference" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="overview-of-inference-and-prediction" class="section level2 hasAnchor" number="6.1">
<h2><span class="header-section-number">6.1</span> Overview of inference and prediction<a href="inference.html#overview-of-inference-and-prediction" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this chapter we will discuss statistical inference and
prediction. Inference and prediction are often intertwined,
so we discuss them together.</p>
<p><span class="citation">Wasserman (<a href="#ref-wasserman2004all">2004</a>)</span> states</p>
<blockquote>
<p>Statistical inference, or “learning” as it is called in
computer science, is the process of using data to infer
the distribution that generated the data.</p>
</blockquote>
<p>In short, statistical inference focusus on drawing conclusions about the data-generating distribution.</p>
<p>There are two primary types of statistical inference:</p>
<ol style="list-style-type: decimal">
<li>Confidence intervals</li>
<li>Hypothesis tests.</li>
</ol>
<p>We will discuss both types of inference for linear
regression models under standard distributional assumptions.
Appendix <a href="est-infer-review.html#est-infer-review">C</a> provides an overview of
both confidence intervals and hypothesis tests in a more
general context.</p>
<p>We will also discuss prediction in this chapter. While
inference focuses on drawing conclusions about the
data-generating distribution, prediction focuses on
selecting a plausible value or range of values for an
unobserved response. It is common to make predictions using
estimated parameters we find as part of the inferential
process, though this isn’t required.</p>
<p>We will also introduce and discuss solutions for the
multiple comparisons problem, which arises when we make
multiple inferences or predictions simultaneously.</p>
</div>
<div id="some-relevant-distributions" class="section level2 hasAnchor" number="6.2">
<h2><span class="header-section-number">6.2</span> Some relevant distributions<a href="inference.html#some-relevant-distributions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We briefly introduce some notation related to random
variables and distributions that we will need in our
discussion below.</p>
<p>We let <span class="math inline">\(t_{\nu}\)</span> denote a random variable having a <span class="math inline">\(t\)</span>
distribution with <span class="math inline">\(\nu\)</span> degrees of freedom. We will use the
notation <span class="math inline">\(t_{\nu}^{\alpha}\)</span> to denote the <span class="math inline">\(1-\alpha\)</span>
quantile of a <span class="math inline">\(t\)</span> distribution with <span class="math inline">\(\nu\)</span> degrees of
freedom. The <span class="math inline">\(t\)</span> distribution is a symmetric bell-shaped
distribution like the normal distribution but has a larger
standard deviation. As the degrees of freedom of a <span class="math inline">\(t\)</span>
random variable increases it behaves more and more similarly
to a random variable with a standard normal distribution (a
<span class="math inline">\(\mathsf{N}(0,1)\)</span> distribution). Figure <a href="inference.html#fig:tquantile">6.1</a>
displays the density of a <span class="math inline">\(t\)</span> distribution with 10 degrees
of freedom while also indicating the 0.95 quantile of that
distribution. Additional information about the <span class="math inline">\(t\)</span>
distribution is available on Wikipedia at
<a href="https://en.wikipedia.org/wiki/Student%27s_t-distribution" class="uri">https://en.wikipedia.org/wiki/Student%27s_t-distribution</a>.</p>
<div class="figure"><span style="display:block;" id="fig:tquantile"></span>
<img src="A-Progessive-Introduction-to-Linear-Models_files/figure-html/tquantile-1.png" alt="The solid line shows the density of a $t$ random variable with 10 degrees of freedom. The dashed vertical line indicates $t^{0.05}_{10}$, the 0.95 quantile of a $t$ distribution with 10 degrees of freedom. The area to the left of the line is 0.95 while the area to the right is 0.05." width="672" />
<p class="caption">
Figure 6.1: The solid line shows the density of a <span class="math inline">\(t\)</span> random variable with 10 degrees of freedom. The dashed vertical line indicates <span class="math inline">\(t^{0.05}_{10}\)</span>, the 0.95 quantile of a <span class="math inline">\(t\)</span> distribution with 10 degrees of freedom. The area to the left of the line is 0.95 while the area to the right is 0.05.
</p>
</div>
<p>We use the notation <span class="math inline">\(F_{\nu_1, \nu_2}\)</span> to denote a random
variable having an <span class="math inline">\(F\)</span> distribution with <span class="math inline">\(\nu_1\)</span> numerator
degrees of freedom and <span class="math inline">\(\nu_2\)</span> denominator degrees of
freedom. We let <span class="math inline">\(F^{\alpha}_{\nu_1,\nu_2}\)</span> denote the
<span class="math inline">\(1-\alpha\)</span> quantile of an <span class="math inline">\(F\)</span> random variables with <span class="math inline">\(\nu_1\)</span>
numerator degrees of freedom and <span class="math inline">\(\nu_2\)</span> denominator degrees
of freedom. In fact, <span class="math inline">\([t_{\nu}]^2=F_{1,\nu}\)</span>, i.e., the
square of a <span class="math inline">\(t\)</span> random variable with <span class="math inline">\(\nu\)</span> degrees of
freedom is equivalent to an <span class="math inline">\(F\)</span> random variable with <span class="math inline">\(1\)</span>
numerator degree of freedom and <span class="math inline">\(\nu\)</span> denominator degrees of
freedom.</p>
</div>
<div id="properties-betahat" class="section level2 hasAnchor" number="6.3">
<h2><span class="header-section-number">6.3</span> Assumptions and properties of the OLS estimator<a href="inference.html#properties-betahat" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We continue by reviewing some of the properties of
<span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span>, the OLS estimator of the
regression coefficient vector.</p>
<p>We assume that
<span class="math display" id="eq:model-def-inference">\[
\mathbf{y} = \mathbf{X}\boldsymbol{\beta}+\boldsymbol{\epsilon}, \tag{6.1}
\]</span>
using standard matrix notation.</p>
<p>We also assume that the model in Equation
<a href="inference.html#eq:model-def-inference">(6.1)</a> is correct (i.e., we have
correctly specified the true model that generated the data)
and that
<span class="math display" id="eq:error-assumption-inference">\[
\boldsymbol{\epsilon}\mid \mathbf{X}\sim \mathsf{N}(\mathbf{0}_{n\times 1},\sigma^2 \mathbf{I}_{n\times n}).  \tag{6.2}
\]</span>
This assumption applies to all errors, so we believe that
all errors, observed and future, will have mean 0, variance
<span class="math inline">\(\sigma^2\)</span>, will be uncorrelated, and have a normal
distribution.</p>
<p>Under these assumptions, we showed in Chapter
<a href="linear-model-theory.html#linear-model-theory">5</a> that</p>
<p><span class="math display">\[
\mathbf{y}\mid \mathbf{X}\sim \mathsf{N}(\mathbf{X}\boldsymbol{\beta}, \sigma^2 \mathbf{I}_{n\times n}).
\]</span> and
<span class="math display" id="eq:prop-betahat">\[\hat{\boldsymbol{\beta}}\mid \mathbf{X} \sim \mathsf{N}(\boldsymbol{\beta}, \sigma^2(\mathbf{X}^T\mathbf{X})^{-1}).
\tag{6.3}
\]</span></p>
</div>
<div id="parametric-confidence-intervals-for-regression-coefficients" class="section level2 hasAnchor" number="6.4">
<h2><span class="header-section-number">6.4</span> Parametric confidence intervals for regression coefficients<a href="inference.html#parametric-confidence-intervals-for-regression-coefficients" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="tci" class="section level3 hasAnchor" number="6.4.1">
<h3><span class="header-section-number">6.4.1</span> Standard <span class="math inline">\(t\)</span>-based confidence intervals<a href="inference.html#tci" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Under the assumptions in Equations
<a href="inference.html#eq:model-def-inference">(6.1)</a> and
<a href="inference.html#eq:error-assumption-inference">(6.2)</a>, we can prove (though
we won’t) that <span class="math display">\[
\frac{\hat{\beta}_j-\beta_j}{\hat{\mathrm{se}}(\hat{\beta}_j)}\sim t_{n-p}, \quad j=0,1,\ldots,p-1,
\]</span></p>
<p>where
<span class="math inline">\(\hat{\mathrm{se}}(\hat{\beta}_j)=\hat{\sigma}\sqrt{(\mathbf{X}^T\mathbf{X})^{-1}_{j+1,j+1}}\)</span>
is the estimated standard error of <span class="math inline">\(\hat{\beta}_j\)</span>. Recall
that estimated standard error is the estimated standard
deviation of the sampling distribution of <span class="math inline">\(\hat{\beta}_j\)</span>.
Also, recall that the notation
<span class="math inline">\((\mathbf{X}^T\mathbf{X})^{-1}_{j+1,j+1}\)</span> indicates the
element in row <span class="math inline">\(j+1\)</span>, column <span class="math inline">\(j+1\)</span>, of the matrix
<span class="math inline">\((\mathbf{X}^T\mathbf{X})^{-1}\)</span>. Thus,
<span class="math inline">\((\hat{\beta}_j-\beta_j)/\hat{\mathrm{se}}(\hat{\beta}_j)\)</span>
is a pivotal quantity with a <span class="math inline">\(t\)</span> distribution, and it can be
used to derive a confidence interval</p>
<p>A confidence interval for <span class="math inline">\(\beta_j\)</span> with confidence level
<span class="math inline">\(1-\alpha\)</span> is given by the expression
<span class="math display" id="eq:t-ci-betas">\[
\hat{\beta}_j \pm t^{\alpha/2}_{n-p} \hat{\mathrm{se}}(\hat{\beta}_j),\quad j=0,1,\ldots,p-1.
\tag{6.4}
\]</span>
It is critical to note that the <span class="math inline">\(1-\alpha\)</span> confidence
level refers to the procedure for a single interval. The confidence level for a procedure producing a family of intervals will be less than <span class="math inline">\(1-\alpha\)</span> without proper adjustment. We discuss this issue in more detail in Section <a href="inference.html#mcp">6.5</a>.</p>
<p>The <code>confint</code> function returns confidence intervals for the
regression coefficients of a fitted model. Technically, the
<code>confint</code> function is a generic function that has methods
for many different object classes, but we only discuss its
usage with <code>lm</code> objects. The <code>confint</code> function has 3 main
arguments:</p>
<ul>
<li><code>object</code>: a fitted model object. In our case, the object
produced by the <code>lm</code> function.</li>
<li><code>parm</code>: a vector of numbers or names indicating the
parameters for which we want to construct confidence
intervals. By default, confidence intervals are
constructed for all parameters.</li>
<li><code>level</code>: the confidence level desired for the confidence
interval. The default value is <code>0.95</code>, which will
produce 95% confidence intervals.</li>
</ul>
<p>We once again use the <code>penguins</code> data from the
<strong>palmerpenguins</strong> package <span class="citation">(<a href="#ref-R-palmerpenguins">Horst, Hill, and Gorman 2022</a>)</span> to illustrate
what we have learned. Consider the regression model <span class="math display">\[
\begin{aligned}
&amp;E(\mathtt{bill\_length\_mm}\mid \mathtt{body\_mass\_g}, \mathtt{flipper\_length\_mm}) \\
&amp;=\beta_0+\beta_1 \mathtt{body\_mass\_g} + \beta_2 \mathtt{flipper\_length\_mm}.
\end{aligned}
\]</span></p>
<p>We estimate the parameters of this model in R using the code
below.</p>
<div class="sourceCode" id="cb159"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb159-1"><a href="inference.html#cb159-1" tabindex="-1"></a><span class="co"># load data</span></span>
<span id="cb159-2"><a href="inference.html#cb159-2" tabindex="-1"></a><span class="fu">data</span>(penguins, <span class="at">package =</span> <span class="st">&quot;palmerpenguins&quot;</span>)</span>
<span id="cb159-3"><a href="inference.html#cb159-3" tabindex="-1"></a><span class="co"># fit model</span></span>
<span id="cb159-4"><a href="inference.html#cb159-4" tabindex="-1"></a>mlmod <span class="ot">&lt;-</span> <span class="fu">lm</span>(bill_length_mm <span class="sc">~</span> body_mass_g <span class="sc">+</span> flipper_length_mm, <span class="at">data =</span> penguins)</span></code></pre></div>
<p>We obtain the 95% confidence intervals for the 3 regression
coefficients by running the code below.</p>
<div class="sourceCode" id="cb160"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb160-1"><a href="inference.html#cb160-1" tabindex="-1"></a><span class="fu">confint</span>(mlmod)</span>
<span id="cb160-2"><a href="inference.html#cb160-2" tabindex="-1"></a><span class="do">##                           2.5 %      97.5 %</span></span>
<span id="cb160-3"><a href="inference.html#cb160-3" tabindex="-1"></a><span class="do">## (Intercept)       -1.244658e+01 5.573192182</span></span>
<span id="cb160-4"><a href="inference.html#cb160-4" tabindex="-1"></a><span class="do">## body_mass_g       -4.534709e-04 0.001777908</span></span>
<span id="cb160-5"><a href="inference.html#cb160-5" tabindex="-1"></a><span class="do">## flipper_length_mm  1.582365e-01 0.285494420</span></span></code></pre></div>
<p>The 95% confidence interval for the intercept parameter is
[-12.45, 5.58]. We are 95% confident that the mean penguin
bill length is between -12.25 and 5.58 mm for a penguin with
a body mass of 0 g and a flipper length of 0 mm. (This
really isn’t sensible).</p>
<p>The 95% confidence interval for the <code>body_mass_g</code>
coefficient is [-0.00046, 0.002]. We are 95% confident the
regression coefficient for <code>body_mass_g</code> is between -0.00046
and 0.002, assuming the <code>flipper_length_mm</code> regressor is
also in the model.</p>
<p>If we wanted to get the 90% confidence interval for the
<code>flipper_length_mm</code> coefficient by itself, we could use
either of the commands shown below.</p>
<div class="sourceCode" id="cb161"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb161-1"><a href="inference.html#cb161-1" tabindex="-1"></a><span class="co"># two styles for determining the CI for a single parameter (at a 90% level)</span></span>
<span id="cb161-2"><a href="inference.html#cb161-2" tabindex="-1"></a><span class="fu">confint</span>(mlmod, <span class="at">parm =</span> <span class="dv">3</span>, <span class="at">level =</span> <span class="fl">0.90</span>)</span>
<span id="cb161-3"><a href="inference.html#cb161-3" tabindex="-1"></a><span class="do">##                         5 %      95 %</span></span>
<span id="cb161-4"><a href="inference.html#cb161-4" tabindex="-1"></a><span class="do">## flipper_length_mm 0.1685112 0.2752197</span></span>
<span id="cb161-5"><a href="inference.html#cb161-5" tabindex="-1"></a><span class="fu">confint</span>(mlmod, <span class="at">parm =</span> <span class="st">&quot;flipper_length_mm&quot;</span>, <span class="at">level =</span> <span class="fl">0.90</span>)</span>
<span id="cb161-6"><a href="inference.html#cb161-6" tabindex="-1"></a><span class="do">##                         5 %      95 %</span></span>
<span id="cb161-7"><a href="inference.html#cb161-7" tabindex="-1"></a><span class="do">## flipper_length_mm 0.1685112 0.2752197</span></span></code></pre></div>
<p>We discuss how to “manually” construct these intervals using
R in Section <a href="inference.html#manual-t-cis">6.11.1</a>.</p>
</div>
</div>
<div id="mcp" class="section level2 hasAnchor" number="6.5">
<h2><span class="header-section-number">6.5</span> The multiple comparisons problem<a href="inference.html#mcp" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Our linear models typically have multiple regression
coefficients, and thus, we typically want to construct
confidence intervals for all of the coefficients.</p>
<p>While individual confidence intervals have utility in
providing us with plausible values of the unknown
coefficients, the confidence level of the procedure
described in Section <a href="inference.html#tci">6.4.1</a> is only valid for a single
interval. Since we are constructing multiple intervals, the
simultaneous confidence level of the procedure for the
family of intervals is less than <span class="math inline">\(1-\alpha\)</span>. This is an
example of the multiple comparisons problem.</p>
<p>A <strong>multiple comparisons problem</strong> occurs anytime we make
multiple inferences (confidence intervals, hypothesis tests,
prediction intervals, etc.). We are more likely to draw
erroneous conclusions if we do not adjust for the fact that
we are making multiple inferential statements. E.g., a
confidence interval procedure with level 0.95 will produce
intervals that contain the target parameter with probability
0.95. If we construct two confidence intervals with level
0.95, then the family-wise confidence level (i.e., the
probability that both intervals simultaneously contain their
respective target parameters) will be less than 0.95. (We
can guarantee that our family-wise confidence level will be
at least 0.90, but we can’t determine the exact value
without more information). In general, the <strong>family-wise
confidence level</strong> is the probability that a confidence
interval procedure produces a family of intervals that
simultaneously contain their target parameter. The
family-wise confidence level is also known as the
<strong>simultaneous</strong> or <strong>overall</strong> confidence level.</p>
<p>A <strong>multiple comparisons procedure</strong> is a procedure designed
to adjust for multiple inferences. In the context of
confidence intervals, a multiple comparisons procedure will
produce a family of intervals that have a family-wise
confidence level above some threshold. We discuss two basic
multiple comparisons procedures for confidence intervals
below.</p>
<div id="adjusted-cis-betas" class="section level3 hasAnchor" number="6.5.1">
<h3><span class="header-section-number">6.5.1</span> Adjusted confidence intervals for regression coefficients<a href="inference.html#adjusted-cis-betas" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><span class="citation">Bonferroni (<a href="#ref-bonferroni1936">1936</a>)</span> proposed a simple multiple comparisons
procedure that is applicable in many contexts. This general
procedure is known as the <strong>Bonferroni correction</strong>. We
describe its application below.</p>
<p>Suppose we are constructing <span class="math inline">\(k\)</span> confidence intervals
simultaneously. We control the family-wise confidence level
of our intervals at <span class="math inline">\(1-\alpha\)</span> if we construct the
individual confidence intervals with the level <span class="math inline">\(1-\alpha/k\)</span>.
We sketch a proof of this below.</p>
<p>Boole’s inequality <span class="citation">(<a href="#ref-boole">Boole 1847</a>)</span> states that for a countable set
of events <span class="math inline">\(A_1, A_2, A_3 \ldots\)</span>,
<span class="math display">\[P(\cup_{j=1}^\infty A_j) \leq \sum_{j=1}^\infty P(A_j).\]</span>
This is a generalization of the fact that <span class="math display">\[
P(A \cup B) = P(A) + P(B) - P(A\cap B) \leq P(A) + P(B)
\]</span> for two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>. We can use Boole’s inequality
to show that the Bonferroni correction controls the
family-wise confidence level of our confidence intervals at
<span class="math inline">\(1-\alpha\)</span>.</p>
<p>Suppose that we construct a family of <span class="math inline">\(k\)</span> confidence
intervals with individual confidence level <span class="math inline">\(1-\alpha/k\)</span> (and
all assumptions are satisfied.) Then the probability that
the confidence interval procedure for a specific interval
doesn’t produce an interval containing the target parameter is <span class="math inline">\(\alpha/k\)</span>. Then <span class="math display">\[
\begin{aligned}
&amp; P(\mbox{All }k\mbox{ intervals contain the target parameter}) \\
&amp; = 1 - P(\mbox{At least one of the }k\mbox{ intervals misses the target parameter}) \\
&amp; = 1 - P(\cup_{j=1}^k \mbox{interval }j\mbox{ misses the target parameter}) \\
&amp; \geq 1 - \sum_{j=1}^k P(\mbox{interval }j\mbox{ misses the target parameter}) \\
&amp; = 1 - k(\alpha/k) \\
&amp;= 1-\alpha.
\end{aligned}
\]</span> Thus, the family-wise confidence level of all <span class="math inline">\(k\)</span>
intervals is AT LEAST <span class="math inline">\(1-\alpha\)</span> when the Bonferroni
correction is used.</p>
<p>The Bonferroni correction is known to be conservative, which
means that the family-wise confidence level is typically
much larger than <span class="math inline">\(1-\alpha\)</span>. This might sound like a
desirable property, but conservative methods can have low
power. In the context of our confidence intervals, this
means our intervals are much wider than they need to be, so
we aren’t able to draw precise conclusions about the
plausible values of our regression coefficients.</p>
<p>Let’s construct simultaneous confidence intervals for our
<code>penguins</code> example using the Bonferroni correction. If we
want to control the family-wise confidence level of our
<span class="math inline">\(k=3\)</span> intervals at <span class="math inline">\(0.95\)</span>, then <span class="math inline">\(\alpha = 0.05\)</span> and the
Bonferroni correction suggests that we should construct the
individual intervals at a confidence level of
<span class="math inline">\(1-0.05/3=0.983\)</span>. We construct the Bonferroni-adjusted
confidence intervals using the code below.</p>
<div class="sourceCode" id="cb162"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb162-1"><a href="inference.html#cb162-1" tabindex="-1"></a><span class="co"># Simultaneous 95% confidence intervals for mlmod</span></span>
<span id="cb162-2"><a href="inference.html#cb162-2" tabindex="-1"></a><span class="fu">confint</span>(mlmod, <span class="at">level =</span> <span class="dv">1</span> <span class="sc">-</span> <span class="fl">0.05</span><span class="sc">/</span><span class="dv">3</span>)</span>
<span id="cb162-3"><a href="inference.html#cb162-3" tabindex="-1"></a><span class="do">##                         0.833 %    99.167 %</span></span>
<span id="cb162-4"><a href="inference.html#cb162-4" tabindex="-1"></a><span class="do">## (Intercept)       -1.445714e+01 7.583749811</span></span>
<span id="cb162-5"><a href="inference.html#cb162-5" tabindex="-1"></a><span class="do">## body_mass_g       -7.024372e-04 0.002026874</span></span>
<span id="cb162-6"><a href="inference.html#cb162-6" tabindex="-1"></a><span class="do">## flipper_length_mm  1.440377e-01 0.299693234</span></span></code></pre></div>
<p>Alternatively, we can use the <code>confint_adjust</code> function from
the <strong>api2lm</strong> package <span class="citation">(<a href="#ref-R-api2lm">French 2023</a>)</span> to construct these
intervals. The <code>confint_adjust</code> function works identically to
the <code>confint</code> function except that it has an additional
argument to indicate the type of adjustment to make when
constructing the confidence intervals. Specifying
<code>method = "bonferroni"</code> will produce Bonferroni-corrected
intervals, as demonstrated in the code below.</p>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb163-1"><a href="inference.html#cb163-1" tabindex="-1"></a><span class="fu">library</span>(api2lm)</span>
<span id="cb163-2"><a href="inference.html#cb163-2" tabindex="-1"></a><span class="fu">confint_adjust</span>(mlmod, <span class="at">method =</span> <span class="st">&quot;bonferroni&quot;</span>)</span>
<span id="cb163-3"><a href="inference.html#cb163-3" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb163-4"><a href="inference.html#cb163-4" tabindex="-1"></a><span class="do">## Bonferroni-adjusted confidence intervals</span></span>
<span id="cb163-5"><a href="inference.html#cb163-5" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb163-6"><a href="inference.html#cb163-6" tabindex="-1"></a><span class="do">## Family-wise confidence level of at least 0.95 </span></span>
<span id="cb163-7"><a href="inference.html#cb163-7" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb163-8"><a href="inference.html#cb163-8" tabindex="-1"></a><span class="do">##               term           lwr         upr</span></span>
<span id="cb163-9"><a href="inference.html#cb163-9" tabindex="-1"></a><span class="do">##        (Intercept) -1.445714e+01 7.583749811</span></span>
<span id="cb163-10"><a href="inference.html#cb163-10" tabindex="-1"></a><span class="do">##        body_mass_g -7.024372e-04 0.002026874</span></span>
<span id="cb163-11"><a href="inference.html#cb163-11" tabindex="-1"></a><span class="do">##  flipper_length_mm  1.440377e-01 0.299693234</span></span></code></pre></div>
<p><span class="citation">Working and Hotelling (<a href="#ref-workinghotelling">1929</a>)</span> developed another multiple comparisons
procedure that can be used to preserve the family-wise
confidence level of the intervals at <span class="math inline">\(1-\alpha\)</span>. The
Working-Hotelling multiple comparisons procedure is valid
for ALL linear combinations of the regression coefficients,
meaning that we can construct an arbitrarily large number of
confidence intervals for linear combinations of the
regression coefficients with this procedure and the
family-wise confidence level will be at least <span class="math inline">\(1-\alpha\)</span>
<span class="citation">(<a href="#ref-alr4">Weisberg 2014</a>)</span>.</p>
<p>The Working-Hotelling procedure guarantees that if we
construct the individual confidence intervals in the
following way, then the family-wise confidence level will be
at least <span class="math inline">\(1-\alpha\)</span>: <span class="math display">\[
\hat{\beta}_j \pm \sqrt{p F^\alpha_{p,n-p}} \hat{\mathrm{se}}(\hat{\beta}_j),\quad j=0,1,\ldots,p-1. (\#eq:wh-ci-betas)
\]</span></p>
<p>The <code>confint_adjust</code> function from the <strong>api2lm</strong> package
will produce these intervals when setting the <code>method</code>
argument to <code>"wh"</code>. We construct Working-Hotelling-adjusted
intervals with family-wise confidence level of at least 0.95
for the <code>penguins</code> example using the code below.</p>
<div class="sourceCode" id="cb164"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb164-1"><a href="inference.html#cb164-1" tabindex="-1"></a><span class="co"># 95% family-wise CIs using Working-Hotelling</span></span>
<span id="cb164-2"><a href="inference.html#cb164-2" tabindex="-1"></a><span class="fu">confint_adjust</span>(mlmod, <span class="at">method =</span> <span class="st">&quot;wh&quot;</span>)</span>
<span id="cb164-3"><a href="inference.html#cb164-3" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb164-4"><a href="inference.html#cb164-4" tabindex="-1"></a><span class="do">## Working-Hotelling-adjusted confidence intervals</span></span>
<span id="cb164-5"><a href="inference.html#cb164-5" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb164-6"><a href="inference.html#cb164-6" tabindex="-1"></a><span class="do">## Family-wise confidence level of at least 0.95 </span></span>
<span id="cb164-7"><a href="inference.html#cb164-7" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb164-8"><a href="inference.html#cb164-8" tabindex="-1"></a><span class="do">##               term           lwr         upr</span></span>
<span id="cb164-9"><a href="inference.html#cb164-9" tabindex="-1"></a><span class="do">##        (Intercept) -1.630614e+01 9.432751051</span></span>
<span id="cb164-10"><a href="inference.html#cb164-10" tabindex="-1"></a><span class="do">##        body_mass_g -9.313981e-04 0.002255835</span></span>
<span id="cb164-11"><a href="inference.html#cb164-11" tabindex="-1"></a><span class="do">##  flipper_length_mm  1.309798e-01 0.312751116</span></span></code></pre></div>
<p>In this example, the Bonferroni-adjusted intervals are
narrower than the Working-Hotelling-adjusted intervals. The
Working-Hotelling intervals tends to be narrower for small
<span class="math inline">\(p\)</span> (e.g., <span class="math inline">\(p=1\)</span> or <span class="math inline">\(2\)</span>) and small <span class="math inline">\(n-p\)</span> (e.g., <span class="math inline">\(n-p = 1\)</span> or
<span class="math inline">\(2\)</span>) <span class="citation">(<a href="#ref-bon_vs_scheffe">Mi and Sampson 1993</a>)</span>. Additionally, as the number of
intervals increases, the Working-Hotelling intervals will
eventually be narrower than the Bonferroni-adjusted
intervals.</p>
</div>
</div>
<div id="prediction-mean-response-versus-new-response" class="section level2 hasAnchor" number="6.6">
<h2><span class="header-section-number">6.6</span> Prediction: mean response versus new response<a href="inference.html#prediction-mean-response-versus-new-response" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>It is common to make two types of predictions in a
regression context: prediction of a mean response and
prediction of a new response. In either context, we want to
make predictions with respect to a specific combination of
regressor values, which we denote <span class="math inline">\(\mathbf{x}_0\)</span>. Using our
previous notation, the mean response for a specific
combination of regressors is denoted
<span class="math inline">\(E(Y\mid \mathbb{X}=\mathbf{x}_0)\)</span>. We do not have notation
to describe a new response for a specific combination of
regressor values, so we will use the notation
<span class="math inline">\(Y(\mathbf{x}_0)\)</span>.</p>
<p><span class="math inline">\(E(Y\mid \mathbb{X}=\mathbf{x}_0)\)</span> represents the average
response when the regressor values are <span class="math inline">\(\mathbf{x}_0\)</span>.
Conceptually, this is the number we would get if were able
to determine the average of an infinite number of responses
with regressor values being fixed at <span class="math inline">\(\mathbf{x}_0\)</span>.</p>
<p><span class="math inline">\(Y(\mathbf{x}_0)\)</span> represents the actual response we will
will observe for a new observation with regressor values
<span class="math inline">\(\mathbf{x}_0\)</span>. Conceptually, we can think of
<span class="math inline">\(Y(\mathbf{x}_0)\)</span> as the mean response for that combination
of regressor values plus some error, or more formally, <span class="math display">\[
Y(\mathbf{x}_0)=E(Y\mid \mathbb{X}=\mathbf{x}_0)+\epsilon(\mathbf{x}_0),
\]</span> where <span class="math inline">\(\epsilon(\mathbf{x_0})\)</span> denotes the error for our
new observation.</p>
<p>Suppose we want to rent a new apartment or buy a new house.
If we look through the available listings, we will likely
filter our search results by certain characteristics. We
might limit our search to dwellings with 3 bedrooms, 2
bathrooms, that are within a certain distance of public
transportation, and have a certain amount of square footage.
If we averaged the monthly rent or asking price of all the
dwellings matching our specifications, then that would be an
approximation of the mean response for that combination of specifications (i.e., regressors). We would need all the
possible dwellings matching those characteristics to get the
true mean. This average would give us an idea of the
“typical” price of dwellings with those characteristics. On
the other hand, we likely want to know the price of the
dwelling we actually end up in. This is the “new response”
we want to predict.</p>
<p>Though we can discuss predictions for both the mean response
and a new response, it is common to distinguish the two
scenarios by using the terminology “estimating the mean
response” to refer to prediction of the the mean and
“prediction a new response” when we want to predict a new
observation. We use this convention in what follows to
distinguish the two contexts.</p>
</div>
<div id="parametric-ci-mean-response" class="section level2 hasAnchor" number="6.7">
<h2><span class="header-section-number">6.7</span> Confidence interval for the mean response<a href="inference.html#parametric-ci-mean-response" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Consider a typical linear regression model with <span class="math inline">\(p\)</span>
regression coefficients given by</p>
<p><span class="math display">\[E(Y|\mathbb{X})=\beta_0+\beta_1 X_1 + \ldots \beta_{p-1} X_{p-1}.\]</span></p>
<p>We want to estimate the mean response for a specific
combination of regressor values. The mean response for that
combination of regressors is obtained via the equivalent
expressions</p>
<p><span class="math display">\[
\begin{aligned}
E(Y\mid \mathbb{X}=\mathbf{x}_0) &amp;= \beta_0 + \sum_{j=1}^{p-1}x_{0,j}\beta_j \\
&amp;= \mathbf{x}_0^T \boldsymbol{\beta}.
\end{aligned}
\]</span></p>
<p>To simplify our notation, we drop the “<span class="math inline">\(\mathbb{X}=\)</span>” in our
discussion below, so
<span class="math inline">\(E(Y\mid \mathbb{X}=\mathbf{x}_0)\equiv E(Y\mid \mathbf{x}_0)\)</span>.</p>
<p>What does <span class="math inline">\(E(Y\mid \mathbf{x}_0)\)</span> represent? It represents
the average response we will observe if we somehow managed
to observe infinitely many responses with
<span class="math inline">\(\mathbb{X}=\mathbf{x}_0\)</span>.</p>
<p>The Gauss-Markov Theorem discussed in Chapter
<a href="linear-model-estimation.html#linear-model-estimation">3</a> indicates that the best
linear unbiased estimator of the mean response is given by
the equation<span class="math display">\[
\begin{aligned}
\hat{E}(Y\mid \mathbf{x}_0) &amp;= \hat{\beta}_0 + \sum_{j=1}^{p-1}x_{0,j}\hat{\beta}_j \\
&amp;= \mathbf{x}_0^T \hat{\boldsymbol{\beta}},
\end{aligned}
\]</span></p>
<p>which replaces the unknown, true coefficients by their OLS
estimates.</p>
<p>We want to create a confidence interval for
<span class="math inline">\(E(Y\mid \mathbf{x}_0)\)</span>. If we divide the estimation error
of the mean response, i.e.,
<span class="math inline">\(E(Y\mid \mathbf{x}_0)-\hat{E}(Y\mid \mathbf{x}_0)\)</span>, by its
estimated standard deviation, then we obtain a pivotal
quantity. More specifically, we have</p>
<p><span class="math display">\[
\frac{E(Y\mid \mathbf{x}_0)-\hat{E}(Y\mid \mathbf{x}_0)}{\sqrt{\hat{\mathrm{var}}\left(E(Y\mid \mathbf{x}_0)-\hat{E}(Y\mid \mathbf{x}_0)\right)}} = \frac{E(Y\mid \mathbf{x}_0)- \mathbf{x}_0^T \hat{\boldsymbol{\beta}}}{ \hat{\mathrm{se}}(\mathbf{x}_0^T\hat{\boldsymbol{\beta}})}\sim t_{n-p},
\]</span></p>
<p>with</p>
<p><span class="math display" id="eq:sehat-est-mean">\[
\hat{\mathrm{se}}(\mathbf{x}_0^T\hat{\boldsymbol{\beta}})=\hat{\sigma}\sqrt{\mathbf{x}_0^T (\mathbf{X}^T \mathbf{X})^{-1}\mathbf{x}_0}. \tag{6.5}
\]</span></p>
<p>A confidence interval for <span class="math inline">\(E(Y\mid \mathbf{x}_0)\)</span> with
confidence level <span class="math inline">\(1-\alpha\)</span> is given by the expression</p>
<p><span class="math display" id="eq:t-ci-mean-response">\[
\mathbf{x}_0^T\hat{\boldsymbol{\beta}} \pm t^{\alpha/2}_{n-p} \hat{\mathrm{se}}(\mathbf{x}_0^T\hat{\boldsymbol{\beta}}). \tag{6.6}
\]</span></p>
<p>The <code>predict</code> function is a generic function used to make
predictions based on fitted models. We can use this function
to estimate the mean response for multiple combinations of
predictor variables, compute the estimated standard error of
each estimate, and obtain confidence intervals for the mean
response. The primary arguments to the <code>lm</code> method for
<code>predict</code> are:</p>
<ul>
<li><code>object</code>: A fitted model from the <code>lm</code> function.</li>
<li><code>newdata</code>: A data frame of predictor values. All
predictors used in the formula used to fit <code>object</code> must
be provided. Each row contains the predictor values for
the mean response we want to estimate. If this is not
provided, then the fitted values for each observation
are returned.</li>
<li><code>se.fit</code>: A logical value indicating whether we want to
explicitly compute the standard errors of each estimated
mean, i.e.,
<span class="math inline">\(\hat{\mathrm{se}}(\mathbf{x}_0^T \hat{\boldsymbol{\beta}})\)</span> for
each estimate.</li>
<li><code>interval</code>: The type of interval to compute. The default
is <code>"none"</code>, meaning no interval is provided. Setting
<code>interval = "confidence"</code> will return a confidence
interval for the mean response associated with each row
of <code>newdata</code>. Setting <code>interval = "prediction"</code> will
return a prediction interval for a new response, which
we will discuss in the next section.</li>
<li><code>level</code>: The confidence level of the interval.</li>
</ul>
<p>Run <code>?predict.lm</code> in the Console for additional details
about this function.</p>
<p>We will estimate the mean response for the parallel lines
model previously fit to the <code>penguins</code> data. We do this to
emphasize the fact that the <code>predict</code> function asks us to
specify the values of the <em>predictor</em> variables for each
estimate we want to make, not the complete set of
regressors.</p>
<p>Recall that in Section <a href="linear-model-estimation.html#s:penguins-mlr2">3.9</a>, we fit a
parallel lines model to the <code>penguins</code> data that used both
<code>body_mass_g</code> and <code>species</code> to explain the behavior of
<code>bill_length_mm</code>. Letting <span class="math inline">\(D_C\)</span> denote the indicator
variable for the <code>Chinstrap</code> level and <span class="math inline">\(D_G\)</span> denote the
indicator variable for the <code>Gentoo</code> level, the fitted
parallel lines model was <span class="math display">\[
\begin{aligned}
&amp;\hat{E}(\mathtt{bill\_length\_mm} \mid \mathtt{body\_mass\_g}, \mathtt{species})\\
&amp;= 24.92 + 0.004 \mathtt{body\_mass\_g} + 9.92 D_C + 3.56 D_G.
\end{aligned}
\]</span> We fit this model below, assigning it the name <code>lmodp</code>.</p>
<div class="sourceCode" id="cb165"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb165-1"><a href="inference.html#cb165-1" tabindex="-1"></a><span class="co"># fit parallel lines model to penguins data</span></span>
<span id="cb165-2"><a href="inference.html#cb165-2" tabindex="-1"></a>lmodp <span class="ot">&lt;-</span> <span class="fu">lm</span>(bill_length_mm <span class="sc">~</span> body_mass_g <span class="sc">+</span> species,</span>
<span id="cb165-3"><a href="inference.html#cb165-3" tabindex="-1"></a>            <span class="at">data =</span> penguins)</span>
<span id="cb165-4"><a href="inference.html#cb165-4" tabindex="-1"></a><span class="fu">coef</span>(lmodp)</span>
<span id="cb165-5"><a href="inference.html#cb165-5" tabindex="-1"></a><span class="do">##      (Intercept)      body_mass_g speciesChinstrap </span></span>
<span id="cb165-6"><a href="inference.html#cb165-6" tabindex="-1"></a><span class="do">##     24.919470977      0.003748497      9.920884113 </span></span>
<span id="cb165-7"><a href="inference.html#cb165-7" tabindex="-1"></a><span class="do">##    speciesGentoo </span></span>
<span id="cb165-8"><a href="inference.html#cb165-8" tabindex="-1"></a><span class="do">##      3.557977539</span></span></code></pre></div>
<p>Let’s estimate the mean response for the “typical”
<code>body_mass_g</code> of each <code>species</code>. We compute the mean
<code>body_mass_g</code> of each <code>species</code> using the code below,
assigning the resulting data frame the name <code>newpenguins</code>.
We use the <code>group_by</code> and <code>summarize</code> functions from the
<strong>dplyr</strong> package <span class="citation">(<a href="#ref-R-dplyr">Wickham et al. 2023</a>)</span> to simplify this process.</p>
<div class="sourceCode" id="cb166"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb166-1"><a href="inference.html#cb166-1" tabindex="-1"></a><span class="co"># mean body_mass_g of each species</span></span>
<span id="cb166-2"><a href="inference.html#cb166-2" tabindex="-1"></a>newpenguins <span class="ot">&lt;-</span> penguins <span class="sc">|&gt;</span></span>
<span id="cb166-3"><a href="inference.html#cb166-3" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">group_by</span>(species) <span class="sc">|&gt;</span></span>
<span id="cb166-4"><a href="inference.html#cb166-4" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">summarize</span>(<span class="at">body_mass_g =</span> <span class="fu">mean</span>(body_mass_g, <span class="at">na.rm =</span> <span class="cn">TRUE</span>))</span>
<span id="cb166-5"><a href="inference.html#cb166-5" tabindex="-1"></a>newpenguins</span>
<span id="cb166-6"><a href="inference.html#cb166-6" tabindex="-1"></a><span class="do">## # A tibble: 3 × 2</span></span>
<span id="cb166-7"><a href="inference.html#cb166-7" tabindex="-1"></a><span class="do">##   species   body_mass_g</span></span>
<span id="cb166-8"><a href="inference.html#cb166-8" tabindex="-1"></a><span class="do">##   &lt;fct&gt;           &lt;dbl&gt;</span></span>
<span id="cb166-9"><a href="inference.html#cb166-9" tabindex="-1"></a><span class="do">## 1 Adelie          3701.</span></span>
<span id="cb166-10"><a href="inference.html#cb166-10" tabindex="-1"></a><span class="do">## 2 Chinstrap       3733.</span></span>
<span id="cb166-11"><a href="inference.html#cb166-11" tabindex="-1"></a><span class="do">## 3 Gentoo          5076.</span></span></code></pre></div>
<p>We now have a data frame with variables for the two
predictors, <code>species</code> and <code>body_mass_g</code> , used to fit
<code>lmodp</code>. Each row of <code>newpenguins</code> contains the mean
<code>body_mass_g</code> for each level of <code>species</code> and is suitable
for use in the <code>predict</code> function.</p>
<p>In the code below, we estimate the mean <code>bill_length_mm</code>
based on the fitted model in <code>lmodp</code> for the mean
<code>body_mass_g</code> of each level of <code>species</code>. We also choose to
compute the estimated standard errors of each estimate by
setting the <code>se.fit</code> argument to <code>TRUE</code>.</p>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb167-1"><a href="inference.html#cb167-1" tabindex="-1"></a><span class="co"># estimate mean and standard error for 3 combinations of predictors</span></span>
<span id="cb167-2"><a href="inference.html#cb167-2" tabindex="-1"></a><span class="fu">predict</span>(lmodp, <span class="at">newdata =</span> newpenguins, <span class="at">se.fit =</span> <span class="cn">TRUE</span>)</span>
<span id="cb167-3"><a href="inference.html#cb167-3" tabindex="-1"></a><span class="do">## $fit</span></span>
<span id="cb167-4"><a href="inference.html#cb167-4" tabindex="-1"></a><span class="do">##        1        2        3 </span></span>
<span id="cb167-5"><a href="inference.html#cb167-5" tabindex="-1"></a><span class="do">## 38.79139 48.83382 47.50488 </span></span>
<span id="cb167-6"><a href="inference.html#cb167-6" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb167-7"><a href="inference.html#cb167-7" tabindex="-1"></a><span class="do">## $se.fit</span></span>
<span id="cb167-8"><a href="inference.html#cb167-8" tabindex="-1"></a><span class="do">##         1         2         3 </span></span>
<span id="cb167-9"><a href="inference.html#cb167-9" tabindex="-1"></a><span class="do">## 0.1955643 0.2914228 0.2166833 </span></span>
<span id="cb167-10"><a href="inference.html#cb167-10" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb167-11"><a href="inference.html#cb167-11" tabindex="-1"></a><span class="do">## $df</span></span>
<span id="cb167-12"><a href="inference.html#cb167-12" tabindex="-1"></a><span class="do">## [1] 338</span></span>
<span id="cb167-13"><a href="inference.html#cb167-13" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb167-14"><a href="inference.html#cb167-14" tabindex="-1"></a><span class="do">## $residual.scale</span></span>
<span id="cb167-15"><a href="inference.html#cb167-15" tabindex="-1"></a><span class="do">## [1] 2.403134</span></span></code></pre></div>
<p>An Adelie penguin with a body mass of 3700.662 g is
estimated to have a mean bill length of 38.79 mm with an
estimated standard error of 0.196 mm. A Chinstrap penguin
with a body mass of 3733.09 g is estimated to have a mean
bill length of 48.83 mm with an estimated standard error
of 0.29 mm. A Gentoo penguin with a body mass of 5076.02 g
is estimated to have a mean bill length of 47.50 mm with
an estimated standard error of 0.22 mm.</p>
<p>To compute the 98% confidence intervals of the mean
response for each combination of predictors, we specify
<code>level = 0.98</code> and <code>interval = "confidence"</code> in the
<code>predict</code> function in the code below.</p>
<div class="sourceCode" id="cb168"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb168-1"><a href="inference.html#cb168-1" tabindex="-1"></a><span class="fu">predict</span>(lmodp, <span class="at">newdata =</span> newpenguins, <span class="at">level =</span> <span class="fl">0.98</span>, <span class="at">interval =</span> <span class="st">&quot;confidence&quot;</span>)</span>
<span id="cb168-2"><a href="inference.html#cb168-2" tabindex="-1"></a><span class="do">##        fit      lwr      upr</span></span>
<span id="cb168-3"><a href="inference.html#cb168-3" tabindex="-1"></a><span class="do">## 1 38.79139 38.33427 39.24851</span></span>
<span id="cb168-4"><a href="inference.html#cb168-4" tabindex="-1"></a><span class="do">## 2 48.83382 48.15264 49.51500</span></span>
<span id="cb168-5"><a href="inference.html#cb168-5" tabindex="-1"></a><span class="do">## 3 47.50488 46.99840 48.01136</span></span></code></pre></div>
<p>The 98% confidence interval for the mean bill length of
an Adelie penguin with a body mass of 3700.662 g is [38.33,
39.25] mm. We are 98% confident that the mean bill length of
Adelie penguins with a body mass of 3700.662 g is between
38.33 and 39.25 mm. Note: we are constructing a confidence
interval for the mean bill length of ALL Adelie penguins
with this body mass, i.e., for</p>
<p><span class="math display">\[
E(\mathtt{flipper\_length\_mm}\mid \mathtt{body\_mass\_g} = 3700.662, \mathtt{species} = \mathtt{Adelie}),
\]</span></p>
<p>which is an unknown characteristic of the population of
all Adelie penguins. Similarly, the 98% confidence interval
for the mean bill length of Chinstrap penguins with a
body mass of 3733.09 g is [48.15, 49.52] mm. Lastly, the mean
flipper length of Gentoo penguins with a body mass of
5076.02 g is [46.99, 48.02] mm, with 98% confidence.</p>
<p>We provide details about manually computing confidence
intervals for the mean response in Section
<a href="inference.html#manual-calc-ci-mean-response">6.11.3</a>.</p>
<p>We are once again faced with a multiple comparisons problem
because we are making 3 inferences. To control the
family-wise confidence level of our intervals, we can use
the Bonferroni or Working-Hotelling corrections previously
discussed in Section <a href="inference.html#adjusted-cis-betas">6.5.1</a>. Both
corrections are implemented in the <code>predict_adjust</code> function
in the <strong>api2lm</strong> package, which is intended to work
identically to the <code>predict</code> function, but produces
intervals that adjust for multiple comparisons. The only
additional argument is <code>method</code>, with choices <code>"none"</code> (no
correction), <code>"bonferroni"</code> (Bonferroni adjustment), or
<code>"wh"</code> (Working-Hotelling adjustment). We produce both types
of adjusted intervals in the code below. The
Bonferroni-adjusted confidence intervals are slightly
narrower in this example.</p>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb169-1"><a href="inference.html#cb169-1" tabindex="-1"></a><span class="co"># bonferroni-adjusted confidence intervals for the mean response</span></span>
<span id="cb169-2"><a href="inference.html#cb169-2" tabindex="-1"></a><span class="fu">predict_adjust</span>(lmodp, <span class="at">newdata =</span> newpenguins, <span class="at">level =</span> <span class="fl">0.98</span>,</span>
<span id="cb169-3"><a href="inference.html#cb169-3" tabindex="-1"></a>               <span class="at">interval =</span> <span class="st">&quot;confidence&quot;</span>, <span class="at">method =</span> <span class="st">&quot;bonferroni&quot;</span>)</span>
<span id="cb169-4"><a href="inference.html#cb169-4" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb169-5"><a href="inference.html#cb169-5" tabindex="-1"></a><span class="do">## Bonferroni-adjusted confidence intervals</span></span>
<span id="cb169-6"><a href="inference.html#cb169-6" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb169-7"><a href="inference.html#cb169-7" tabindex="-1"></a><span class="do">## Family-wise confidence level of at least 0.98 </span></span>
<span id="cb169-8"><a href="inference.html#cb169-8" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb169-9"><a href="inference.html#cb169-9" tabindex="-1"></a><span class="do">##        fit      lwr      upr</span></span>
<span id="cb169-10"><a href="inference.html#cb169-10" tabindex="-1"></a><span class="do">## 1 38.79139 38.25751 39.32527</span></span>
<span id="cb169-11"><a href="inference.html#cb169-11" tabindex="-1"></a><span class="do">## 2 48.83382 48.03826 49.62939</span></span>
<span id="cb169-12"><a href="inference.html#cb169-12" tabindex="-1"></a><span class="do">## 3 47.50488 46.91335 48.09641</span></span>
<span id="cb169-13"><a href="inference.html#cb169-13" tabindex="-1"></a><span class="co"># working-hotelling-adjusted confidence intervals for the mean response</span></span>
<span id="cb169-14"><a href="inference.html#cb169-14" tabindex="-1"></a><span class="fu">predict_adjust</span>(lmodp, <span class="at">newdata =</span> newpenguins, <span class="at">level =</span> <span class="fl">0.98</span>,</span>
<span id="cb169-15"><a href="inference.html#cb169-15" tabindex="-1"></a>               <span class="at">interval =</span> <span class="st">&quot;confidence&quot;</span>, <span class="at">method =</span> <span class="st">&quot;wh&quot;</span>)</span>
<span id="cb169-16"><a href="inference.html#cb169-16" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb169-17"><a href="inference.html#cb169-17" tabindex="-1"></a><span class="do">## Working-Hotelling-adjusted confidence intervals</span></span>
<span id="cb169-18"><a href="inference.html#cb169-18" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb169-19"><a href="inference.html#cb169-19" tabindex="-1"></a><span class="do">## Family-wise confidence level of at least 0.98 </span></span>
<span id="cb169-20"><a href="inference.html#cb169-20" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb169-21"><a href="inference.html#cb169-21" tabindex="-1"></a><span class="do">##        fit      lwr      upr</span></span>
<span id="cb169-22"><a href="inference.html#cb169-22" tabindex="-1"></a><span class="do">## 1 38.79139 38.11858 39.46420</span></span>
<span id="cb169-23"><a href="inference.html#cb169-23" tabindex="-1"></a><span class="do">## 2 48.83382 47.83122 49.83642</span></span>
<span id="cb169-24"><a href="inference.html#cb169-24" tabindex="-1"></a><span class="do">## 3 47.50488 46.75941 48.25035</span></span></code></pre></div>
</div>
<div id="pi-new-response" class="section level2 hasAnchor" number="6.8">
<h2><span class="header-section-number">6.8</span> Prediction interval for a new response<a href="inference.html#pi-new-response" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We once again assume the regression model <span class="math display">\[
E(Y|\mathbb{X})=\beta_0+\beta_1 X_1 + \ldots \beta_{p-1} X_{p-1}.
\]</span> We want to predict a new response for a specific
combination of regressor values, <span class="math inline">\(\mathbf{x}_0\)</span>. The new
response will be the mean response for that combination of
regressors, <span class="math inline">\(E(Y\mid \mathbf{x}_0)\)</span>, plus the error for that
observation, <span class="math inline">\(\epsilon(\mathbf{x}_0)\)</span>, i.e., <span class="math display">\[
Y(\mathbf{x}_0)=E(Y\mid \mathbf{x}_0) + \epsilon(\mathbf{x}_0).
\]</span></p>
<p>Thus, our predicted new response, <span class="math inline">\(\hat{Y}(\mathbf{x})\)</span> is
the estimated mean plus the estimated error, i.e., <span class="math display">\[
\hat{Y}(\mathbf{x}_0)=\hat{E}(Y\mid \mathbf{x}_0) + \hat{\epsilon}(\mathbf{x}_0).
\]</span> We have already used
<span class="math inline">\(\hat{E}(Y\mid \mathbf{x}_0)=\mathbf{x}_0^T\hat{\boldsymbol{\beta}}\)</span>
as the estimator for <span class="math inline">\(E(Y\mid \mathbf{x}_0)\)</span> since it is the
best linear unbiased estimator according to the Gauss-Markov
theorem. What should we use for
<span class="math inline">\(\hat{\epsilon}(\mathbf{x}_0)\)</span>? In short, because all of the
errors,
<span class="math inline">\(\epsilon_1, \epsilon_2,\ldots, \epsilon_n, \epsilon(\mathbf{x}_0)\)</span>
are uncorrelated and have a normal distribution with mean zero, our best guess is the mean value of the
errors, which is zero. This is not true when the errors are
correlated, but we do not discuss that in detail. Thus, the
best predictor of a new response is <span class="math display">\[
\begin{aligned}
\hat{Y}(\mathbf{x}_0) &amp;=\hat{E}(Y\mid \mathbf{x}_0) + \hat{\epsilon}(\mathbf{x}_0)\\
&amp;= \mathbf{x}_0^T\hat{\boldsymbol{\beta}} + 0 \\
&amp;= \mathbf{x}_0^T\hat{\boldsymbol{\beta}}.
\end{aligned}
\]</span></p>
<p>We want to create a prediction interval for
<span class="math inline">\(Y(\mathbf{x}_0)\)</span>. A prediction interval is similar to a confidence interval, but the interval estimator is for a random variable (<span class="math inline">\(Y(\mathbf{x}_0)\)</span>) instead of a parameter (<span class="math inline">\(E(Y\mid \mathbf{x}_0)\)</span>).
If we divide the estimation error of the new response, i.e.,
<span class="math inline">\(Y(\mathbf{x}_0)-\hat{Y}(\mathbf{x}_0)\)</span>, by its estimated
standard deviation,
<span class="math inline">\(\widehat{\mathrm{sd}}(Y(\mathbf{x}_0)-\hat{Y}(\mathbf{x}_0))\)</span>,
then we obtain a <span class="math inline">\(t\)</span>-distributed pivotal quantity
<span class="math display">\[
\frac{Y(\mathbf{x}_0)-\hat{Y}(\mathbf{x}_0)}{\widehat{\mathrm{sd}}(Y(\mathbf{x}_0)-\hat{Y}(\mathbf{x}_0))} \sim t_{n-p},
\]</span>
where
<span class="math display" id="eq:sdhat-pred-error">\[
\widehat{\mathrm{sd}}(Y(\mathbf{x}_0)-\hat{Y}(\mathbf{x}_0))=\hat{\sigma}\sqrt{1 + \mathbf{x}_0^T (\mathbf{X}^T \mathbf{X})^{-1}\mathbf{x}_0}. \tag{6.7}
\]</span></p>
<p>The standard deviation of the prediction error is
sometimes known as the <strong>standard error of prediction</strong>, but
we do not use that terminology. A detailed derivation of
<span class="math inline">\(\widehat{\mathrm{sd}}(Y(\mathbf{x}_0)-\hat{Y}(\mathbf{x}_0))\)</span>
is provided in Section <a href="inference.html#new-response-pi-calculations">6.11.4</a>.</p>
<p>A prediction interval for <span class="math inline">\(Y(\mathbf{x}_0)\)</span> with confidence
level <span class="math inline">\(1-\alpha\)</span> is given by the expression <span class="math display">\[
\mathbf{x}_0\hat{\boldsymbol{\beta}} \pm t^{\alpha/2}_{n-p} \hat{\mathrm{sd}}(Y(\mathbf{x}_0)-\hat{Y}(\mathbf{x}_0)). (\#eq:t-pi-new-response)
\]</span></p>
<p>There is a conceptual and mathematical relationship between
the standard deviation of the estimation error for the mean
response and the prediction error for a new observation. If
we compare the expressions for
<span class="math inline">\(\hat{\mathrm{se}}(\mathbf{x}_0^T\hat{\boldsymbol{\beta}})\)</span>
in Equation <a href="inference.html#eq:sehat-est-mean">(6.5)</a> and
<span class="math inline">\(\widehat{\mathrm{sd}}(Y(\mathbf{x}_0)-\hat{Y}(\mathbf{x}_0))\)</span>
in Equation <a href="inference.html#eq:sdhat-pred-error">(6.7)</a>, we see that
that
<span class="math display">\[
\hat{\mathrm{sd}}(Y(\mathbf{x}_0)-\hat{Y}(\mathbf{x}_0)) = \hat{\sigma} + \hat{\mathrm{se}}(\mathbf{x}_0^T\hat{\boldsymbol{\beta}}).
\]</span>
Because of this,
<em>prediction intervals for a new response are always wider
than a confidence interval for the mean response</em> when
considering the same regressor values, <span class="math inline">\(\mathbf{x}_0\)</span>, and
confidence level. Conceptually, prediction intervals are
wider because there are two sources of uncertainty in our
prediction: estimating the mean response and predicting the
error of the new response. Estimating the mean response does
not require us to predict the error of a new response, so
the uncertainty of our estimate is less. We can see that
this is formally true through the derivations provided in
Section <a href="inference.html#new-response-pi-calculations">6.11.4</a>.</p>
<p>The <code>predict</code> function can be used to create predictions and
prediction intervals for a new response in the same way that
it can be used to estimate the mean response and produce
associated confidence intervals. If the <code>interval</code> argument
is <code>"none"</code>, then predictions for a new response are
returned. As we have already seen,
<span class="math inline">\(\hat{E}(Y\mid \mathbf{x}_0)\)</span> and <span class="math inline">\(\hat{Y}(\mathbf{x}_0)\)</span>
are the same number. If the <code>interval</code> argument is
<code>"prediction"</code>, then the predicted new response and
associated prediction interval will be produced for each row
of data supplied to the <code>newdata</code> argument.</p>
<p>Continuing the example started in Section
<a href="inference.html#parametric-ci-mean-response">6.7</a>, we want to predict the
response value for new, unobserved penguins having the
observed mean <code>body_mass_g</code> for each level of <code>species</code>. The
fitted model is stored in <code>lmodp</code> and the data frame with
the predictors for the new responses is stored in
<code>newpenguins</code>. We print the coefficients of the fitted model
and the data frame of new predictors below for clarity.</p>
<div class="sourceCode" id="cb170"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb170-1"><a href="inference.html#cb170-1" tabindex="-1"></a><span class="fu">coef</span>(lmodp)</span>
<span id="cb170-2"><a href="inference.html#cb170-2" tabindex="-1"></a><span class="do">##      (Intercept)      body_mass_g speciesChinstrap </span></span>
<span id="cb170-3"><a href="inference.html#cb170-3" tabindex="-1"></a><span class="do">##     24.919470977      0.003748497      9.920884113 </span></span>
<span id="cb170-4"><a href="inference.html#cb170-4" tabindex="-1"></a><span class="do">##    speciesGentoo </span></span>
<span id="cb170-5"><a href="inference.html#cb170-5" tabindex="-1"></a><span class="do">##      3.557977539</span></span>
<span id="cb170-6"><a href="inference.html#cb170-6" tabindex="-1"></a>newpenguins</span>
<span id="cb170-7"><a href="inference.html#cb170-7" tabindex="-1"></a><span class="do">## # A tibble: 3 × 2</span></span>
<span id="cb170-8"><a href="inference.html#cb170-8" tabindex="-1"></a><span class="do">##   species   body_mass_g</span></span>
<span id="cb170-9"><a href="inference.html#cb170-9" tabindex="-1"></a><span class="do">##   &lt;fct&gt;           &lt;dbl&gt;</span></span>
<span id="cb170-10"><a href="inference.html#cb170-10" tabindex="-1"></a><span class="do">## 1 Adelie          3701.</span></span>
<span id="cb170-11"><a href="inference.html#cb170-11" tabindex="-1"></a><span class="do">## 2 Chinstrap       3733.</span></span>
<span id="cb170-12"><a href="inference.html#cb170-12" tabindex="-1"></a><span class="do">## 3 Gentoo          5076.</span></span></code></pre></div>
<p>In the code below, we predict the <code>bill_length_mm</code> for
new penguins for the predictor values stored in
<code>newpenguins</code> based on the fitted model in <code>lmodp</code>. We also
construct the associated 99% prediction intervals.</p>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb171-1"><a href="inference.html#cb171-1" tabindex="-1"></a><span class="co"># predict new response and compute prediction intervals</span></span>
<span id="cb171-2"><a href="inference.html#cb171-2" tabindex="-1"></a><span class="co"># for 3 combinations of predictors</span></span>
<span id="cb171-3"><a href="inference.html#cb171-3" tabindex="-1"></a><span class="fu">predict</span>(lmodp, <span class="at">newdata =</span> newpenguins,</span>
<span id="cb171-4"><a href="inference.html#cb171-4" tabindex="-1"></a>        <span class="at">interval =</span> <span class="st">&quot;prediction&quot;</span>, <span class="at">level =</span> <span class="fl">0.99</span>)</span>
<span id="cb171-5"><a href="inference.html#cb171-5" tabindex="-1"></a><span class="do">##        fit      lwr      upr</span></span>
<span id="cb171-6"><a href="inference.html#cb171-6" tabindex="-1"></a><span class="do">## 1 38.79139 32.54561 45.03718</span></span>
<span id="cb171-7"><a href="inference.html#cb171-7" tabindex="-1"></a><span class="do">## 2 48.83382 42.56301 55.10464</span></span>
<span id="cb171-8"><a href="inference.html#cb171-8" tabindex="-1"></a><span class="do">## 3 47.50488 41.25442 53.75534</span></span></code></pre></div>
<p>A new Adelie penguin with a body mass of 3700.662 g is
predicted to have a bill length of 38.79 mm. We are 99%
confident that a new Adelie penguins with a body mass of
3700.662 g will have a flipper length between 32.54 and
45.04 mm. Similarly, the 99% prediction interval for the
bill length of a new Chinstrap penguin with a body mass
of 3733.09 g is [48.56, 55.11] mm. The flipper length of a new
Gentoo penguin with a body mass of 5076.02 g is between
41.25 and 53.76 mm with a confidence level of 0.99.</p>
<p>Since we are making 3 predictions, our inferences suffer
from the multiple comparisons problem. To control the
family-wise confidence level of our intervals, we can use
the Bonferroni correction with <span class="math inline">\(k=3\)</span>. The Working-Hotelling
correction discussed in Section <a href="inference.html#adjusted-cis-betas">6.5.1</a>
does not apply to new responses. However, a similar
adjustment proposed by Scheffé does apply <span class="citation">(<a href="#ref-alsm2005">Kutner et al. 2005</a>)</span>. The prediction interval multiplier used for a single prediction interval with confidence level <span class="math inline">\(1-\alpha\)</span> changes from <span class="math inline">\(t^{\alpha/2}_{n-p}\)</span> to <span class="math inline">\(\sqrt{k F^{\alpha}_{k,n-p}}\)</span> to control the family-wise confidence level at <span class="math inline">\(1-\alpha\)</span> for a family of <span class="math inline">\(k\)</span> prediction intervals. Recall that the
Working-Hotelling multiplier was
<span class="math inline">\(\sqrt{p F^{alpha}_{p,n-p}}\)</span>. Thus, the Scheffé
multiplier scales with the number of predictions being made
while the Working-Hotelling multiplier scales with the
number of estimated regression coefficients in the fitted
model.</p>
<p>Both the Bonferroni and Scheffé multiple comparisons
corrections are implemented in the <code>predict_adjust</code> function
in the <strong>api2lm</strong> package. In the prediction interval
setting, we can choose the correction <code>method</code> argument to
be <code>"none"</code> (no correction), <code>"bonferroni"</code> (Bonferroni
adjustment), or <code>"scheffe"</code> (Scheffé adjustment). We produce
both types of adjusted intervals in the code below. The
Bonferroni-adjusted confidence intervals are slightly
narrower in this example.</p>
<div class="sourceCode" id="cb172"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb172-1"><a href="inference.html#cb172-1" tabindex="-1"></a><span class="co"># bonferroni-adjusted prediction intervals for new responses</span></span>
<span id="cb172-2"><a href="inference.html#cb172-2" tabindex="-1"></a><span class="fu">predict_adjust</span>(lmodp, <span class="at">newdata =</span> newpenguins, <span class="at">level =</span> <span class="fl">0.99</span>,</span>
<span id="cb172-3"><a href="inference.html#cb172-3" tabindex="-1"></a>               <span class="at">interval =</span> <span class="st">&quot;prediction&quot;</span>,</span>
<span id="cb172-4"><a href="inference.html#cb172-4" tabindex="-1"></a>               <span class="at">method =</span> <span class="st">&quot;bonferroni&quot;</span>)</span>
<span id="cb172-5"><a href="inference.html#cb172-5" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb172-6"><a href="inference.html#cb172-6" tabindex="-1"></a><span class="do">## Bonferroni-adjusted prediction intervals</span></span>
<span id="cb172-7"><a href="inference.html#cb172-7" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb172-8"><a href="inference.html#cb172-8" tabindex="-1"></a><span class="do">## Family-wise confidence level of at least 0.99 </span></span>
<span id="cb172-9"><a href="inference.html#cb172-9" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb172-10"><a href="inference.html#cb172-10" tabindex="-1"></a><span class="do">##        fit      lwr      upr</span></span>
<span id="cb172-11"><a href="inference.html#cb172-11" tabindex="-1"></a><span class="do">## 1 38.79139 31.66373 45.91905</span></span>
<span id="cb172-12"><a href="inference.html#cb172-12" tabindex="-1"></a><span class="do">## 2 48.83382 41.67760 55.99004</span></span>
<span id="cb172-13"><a href="inference.html#cb172-13" tabindex="-1"></a><span class="do">## 3 47.50488 40.37188 54.63787</span></span>
<span id="cb172-14"><a href="inference.html#cb172-14" tabindex="-1"></a><span class="co"># sheffe-adjusted prediction intervals for new responses</span></span>
<span id="cb172-15"><a href="inference.html#cb172-15" tabindex="-1"></a><span class="fu">predict_adjust</span>(lmodp, <span class="at">newdata =</span> newpenguins, <span class="at">level =</span> <span class="fl">0.99</span>,</span>
<span id="cb172-16"><a href="inference.html#cb172-16" tabindex="-1"></a>               <span class="at">interval =</span> <span class="st">&quot;prediction&quot;</span>,</span>
<span id="cb172-17"><a href="inference.html#cb172-17" tabindex="-1"></a>               <span class="at">method =</span> <span class="st">&quot;scheffe&quot;</span>)</span>
<span id="cb172-18"><a href="inference.html#cb172-18" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb172-19"><a href="inference.html#cb172-19" tabindex="-1"></a><span class="do">## Scheffe-adjusted prediction intervals</span></span>
<span id="cb172-20"><a href="inference.html#cb172-20" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb172-21"><a href="inference.html#cb172-21" tabindex="-1"></a><span class="do">## Family-wise confidence level of at least 0.99 </span></span>
<span id="cb172-22"><a href="inference.html#cb172-22" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb172-23"><a href="inference.html#cb172-23" tabindex="-1"></a><span class="do">##        fit      lwr      upr</span></span>
<span id="cb172-24"><a href="inference.html#cb172-24" tabindex="-1"></a><span class="do">## 1 38.79139 30.60787 46.97492</span></span>
<span id="cb172-25"><a href="inference.html#cb172-25" tabindex="-1"></a><span class="do">## 2 48.83382 40.61751 57.05014</span></span>
<span id="cb172-26"><a href="inference.html#cb172-26" tabindex="-1"></a><span class="do">## 3 47.50488 39.31523 55.69453</span></span></code></pre></div>
</div>
<div id="hypothesis-tests-for-a-single-regression-coefficient" class="section level2 hasAnchor" number="6.9">
<h2><span class="header-section-number">6.9</span> Hypothesis tests for a single regression coefficient<a href="inference.html#hypothesis-tests-for-a-single-regression-coefficient" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>If we assume we are fitting the multiple linear regression model in Equation <a href="inference.html#eq:model-def-inference">(6.1)</a>, then our
model has <span class="math inline">\(p\)</span> regression coefficient
<span class="math inline">\(\beta_0, \beta_1, \ldots, \beta_{p-1}\)</span>. How can we
perform a hypothesis test for exactly one of these
regression coefficients?</p>
<p>Let’s say we wish to test whether, for this model, <span class="math inline">\(\beta_j\)</span>
differs from some constant number <span class="math inline">\(c\)</span> (typically, <span class="math inline">\(c=0\)</span>).
Let
<span class="math inline">\(\boldsymbol{\beta}_{-j}=\boldsymbol{\beta}\setminus{\beta_j}\)</span>,
i.e., <span class="math inline">\(\boldsymbol{\beta}_{-j}\)</span> is the vector of all
regression coefficients except <span class="math inline">\(\beta_j\)</span>.
<span class="math inline">\(\boldsymbol{\beta}_{-j}\)</span> has <span class="math inline">\(p-1\)</span> elements. We can state
the hypotheses we wish to test as
<span class="math display" id="eq:betaj-H0Ha">\[
\begin{aligned}
H_0: \beta_j &amp;= c \mid \boldsymbol{\beta}_{-j}\in\mathbb{R}^{p-1} \\
H_a: \beta_j &amp;\neq c \mid \boldsymbol{\beta}_{-j}\in\mathbb{R}^{p-1}.
\end{aligned}
\tag{6.8}
\]</span>
The first part of the null hypothesis in Equation
<a href="inference.html#eq:betaj-H0Ha">(6.8)</a> states that <span class="math inline">\(\beta_j = c\)</span> while the
first part of the alternative hypothesis assumes that
<span class="math inline">\(\beta_j \neq c\)</span>. But what does the second half of the
hypotheses mean? The vertical bar means “assuming or
conditional on”, similar to the notation you would see in
conditional probabilities or distributions. What this means
is that we are performing the hypothesis test while assuming
that the other coefficients are some real number (possibly
even zero). Why state this at all? Isn’t it implicitly
assumed? No. We could perform a hypothesis test for
<span class="math inline">\(\beta_j\)</span> for many different models that have differing
regressors. By writing out hypotheses in the style of
Equation <a href="inference.html#eq:betaj-H0Ha">(6.8)</a>, we are being very clear that
we are performing a test for <span class="math inline">\(\beta_j\)</span> in the context of the
model that has the regressors associated with
<span class="math inline">\(\boldsymbol{\beta}_{-j}\)</span>. Tests are model specific, so it is important to be clarify the exact model under consideration</p>
<p>Recall that if we make the assumptions in Equation
<a href="inference.html#eq:error-assumption-inference">(6.2)</a>, then</p>
<span class="math display" id="eq:pivot-t-betaj">\[\begin{equation}
\frac{\hat{\beta}_j-\beta_j}{\hat{\mathrm{se}}(\hat{\beta}_j)}\sim t_{n-p}, \quad j=0,1,\ldots,p-1. \tag{6.9}
\end{equation}\]</span>
<p>How do the hypotheses in Equation <a href="inference.html#eq:betaj-H0Ha">(6.8)</a>
affect the pivotal quantity in Equation
<a href="inference.html#eq:pivot-t-betaj">(6.9)</a>? Under the null hypothesis, the
statistic
<span class="math display">\[
T_j = \frac{\hat{\beta}_j-c}{\hat{\mathrm{se}}(\hat{\beta}_j)} \sim t_{n-p}.
\]</span>
Thus, the null distribution of <span class="math inline">\(T_j\)</span> is a <span class="math inline">\(t\)</span>
distribution with <span class="math inline">\(n-p\)</span> degrees of freedom. We emphasize
that this is only true if the assumptions in Equation
<a href="inference.html#eq:error-assumption-inference">(6.2)</a> are true.</p>
<p>The p-value associated with this test is computed via the
equation <span class="math display">\[
p\text{-value} = 2P(t_{n-p}\geq |T_j|).
\]</span> What if we wished to test a one-sided hypothesis? The
p-value for a lower-tailed test is
<span class="math inline">\(p\text{-value}=P(t_{n-p}\leq T_j)\)</span> while the p-value for an
upper-tailed test is <span class="math inline">\(p\text{-value}=P(t_{n-p}\geq T_j)\)</span>.</p>
<p>We will perform a hypothesis test for the model
<span class="math display">\[
\begin{aligned}
&amp;E(\mathtt{bill\_length\_mm}\mid \mathtt{body\_mass\_g}, \mathtt{flipper\_length\_mm}) \\
&amp;=\beta_0+\beta_1 \mathtt{body\_mass\_g} + \beta_2 \mathtt{flipper\_length\_mm}
\end{aligned}
\]</span></p>
<p>for the <code>penguins</code> data. The fitted model is assigned the name <code>mlmod</code>. Suppose we want to test</p>
<p><span class="math display">\[
\begin{aligned}
H_0: &amp;\beta_1 = 0 \mid \beta_0\in \mathbb{R}, \beta_2 \in \mathbb{R} \\
H_a: &amp;\beta_1 \neq 0 \mid \beta_0\in \mathbb{R}, \beta_2 \in \mathbb{R}.
\end{aligned}
\]</span> R conveniently provides this information in the output of
the <code>summary</code> function (specifically, the <code>coefficients</code>
element if we don’t want extra information). We extract this
information from the <code>mlmod</code> object in the code below.</p>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb173-1"><a href="inference.html#cb173-1" tabindex="-1"></a><span class="fu">summary</span>(mlmod)<span class="sc">$</span>coefficients</span>
<span id="cb173-2"><a href="inference.html#cb173-2" tabindex="-1"></a><span class="do">##                        Estimate   Std. Error    t value</span></span>
<span id="cb173-3"><a href="inference.html#cb173-3" tabindex="-1"></a><span class="do">## (Intercept)       -3.4366939266 4.5805531903 -0.7502792</span></span>
<span id="cb173-4"><a href="inference.html#cb173-4" tabindex="-1"></a><span class="do">## body_mass_g        0.0006622186 0.0005672075  1.1675067</span></span>
<span id="cb173-5"><a href="inference.html#cb173-5" tabindex="-1"></a><span class="do">## flipper_length_mm  0.2218654584 0.0323484492  6.8586119</span></span>
<span id="cb173-6"><a href="inference.html#cb173-6" tabindex="-1"></a><span class="do">##                       Pr(&gt;|t|)</span></span>
<span id="cb173-7"><a href="inference.html#cb173-7" tabindex="-1"></a><span class="do">## (Intercept)       4.536070e-01</span></span>
<span id="cb173-8"><a href="inference.html#cb173-8" tabindex="-1"></a><span class="do">## body_mass_g       2.438263e-01</span></span>
<span id="cb173-9"><a href="inference.html#cb173-9" tabindex="-1"></a><span class="do">## flipper_length_mm 3.306943e-11</span></span></code></pre></div>
<p>Moving from left to right, the first column (no name)
indicates the coefficient term under consideration, the
second column (<code>Estimate</code>) provides the estimated
coefficients, the third column (<code>Std. Error</code>) provides the
estimated standard error
(i.e., <span class="math inline">\(\hat{\mathrm{se}}(\hat{\beta}_j)\)</span>) for each coefficient,
the fourth column (<code>t value</code>) provides the test statistic
associated with testing
<span class="math inline">\(H_0: \beta_j = 0 \mid \boldsymbol{\beta}_{-j} \in \mathbb{R}^{p-1}\)</span>
versus a suitable alternative for each coefficient, while
the final column (<code>Pr(&gt;|t|)</code>) provides the two-tailed
p-value associated with this test.</p>
<p>Thus, for our test of the <code>body_mass_g</code> coefficient, the
test statistic is <span class="math inline">\(T_1 = 1.17\)</span> and the associated p-value is
0.24. There is no evidence that the coefficient for
<code>body_mass_g</code> differs from zero, assuming the model also
allows for the inclusion of the intercept and
<code>flipper_length_mm</code> coefficients.</p>
</div>
<div id="hypothesis-tests-for-multiple-regression-coefficients" class="section level2 hasAnchor" number="6.10">
<h2><span class="header-section-number">6.10</span> Hypothesis tests for multiple regression coefficients<a href="inference.html#hypothesis-tests-for-multiple-regression-coefficients" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Suppose we have a standard linear regression model with
<span class="math inline">\(p\)</span> regression coefficients such as the one defined in
Equation <a href="inference.html#eq:model-def-inference">(6.1)</a>. We refer to this
model as the “Complete Model”.</p>
<p>We want to compare the Complete Model to a “Reduced Model”. The Reduced Model is a special case of the Complete Model. Alternatively, we can say the Reduced Model is <em>nested</em> in the Complete Model. We use the abbreviations RM to indicate the Reduced Model and CM to indicate the Complete Model.</p>
<p>The most common examples of Reduced Model are:</p>
<ol style="list-style-type: decimal">
<li>All the coefficients except the intercept are set to
zero.</li>
<li>Some of the coefficients are set to zero.</li>
</ol>
<p>Other examples of a RM set
certain coefficients equal to each other or place other
restrictions on the coefficients.</p>
<p>Let <span class="math inline">\(RSS_{RM}\)</span> denote the RSS of the RM and
<span class="math inline">\(RSS_{CM}\)</span> denote the RSS of the CM. Similarly,
<span class="math inline">\(\mathrm{df}_{RM}\)</span> and <span class="math inline">\(\mathrm{df}_{CM}\)</span> denote the degrees of freedom
associated with the RSS for the RM and CM,
respectively. Recall that the degrees of freedom associated
with a RSS is simply <span class="math inline">\(n\)</span>, the number of observations used to
fit the model, minus the number of estimated regression
coefficients in the model being considered.</p>
<p>We want to perform a hypothesis test involving multiple
regression coefficients in our model. Without be specific or
developing complex notation, we cannot be precise in stating
the hypotheses we wish to test. A general statement of
the hypotheses we will test are:</p>
<p><span class="math display">\[
\begin{aligned}
&amp;H_0: \text{RM is an adequate model for describing the population.} \\
&amp;H_a: \text{CM is a more appropriate model for describing the population.}
\end{aligned}
\]</span></p>
<p>We wish to statistically assess whether we can simplify our
model from <span class="math inline">\(CM\)</span> to <span class="math inline">\(RM\)</span>. If <span class="math inline">\(RM\)</span> doesn’t adequately explain the
patterns of the data, then we will conclude that <span class="math inline">\(CM\)</span> is a
more appropriate model.</p>
<p>If we assume that the assumptions in Equation
<a href="inference.html#eq:error-assumption-inference">(6.2)</a> are true for <span class="math inline">\(RM\)</span> and
that <span class="math inline">\(RM\)</span> is the true model, then</p>
<p><span class="math display" id="eq:f-stat-lh">\[
F=\frac{\frac{RSS_{RM}-RSS_{CM}}{\mathrm{df}_{RM}-\mathrm{df}_{CM}}}{\frac{RSS_{CM}}{\mathrm{df}_{CM}}}=\frac{\frac{RSS_{RM}-RSS_{CM}}{\mathrm{df}_{RM}-\mathrm{df}_{CM}}}{\hat{\sigma}^2_{CM}}\sim F_{\mathrm{df}_{RM}-\mathrm{df}_{CM},\mathrm{df}_{CM}}, \tag{6.10}
\]</span>
where <span class="math inline">\(F_{\mathrm{df}_{RM}-\mathrm{df}_{CM},\mathrm{df}_{CM}}\)</span> is an <span class="math inline">\(F\)</span> random
variable with <span class="math inline">\(\mathrm{df}_{RM}-\mathrm{df}_{CM}\)</span> numerator degrees of freedom and <span class="math inline">\(\mathrm{df}_{CM}\)</span> denominator degrees of freedom and <span class="math inline">\(\hat{\sigma}^2_{CM}\)</span> is the estimated error variance of <span class="math inline">\(CM\)</span>.</p>
<p>The p-value for this test is</p>
<p><span class="math display">\[
p\text{-value}=P(F_{\mathrm{df}_{RM}-\mathrm{df}_{CM},\mathrm{df}_{CM}} \geq F).
\]</span></p>
<p>We consider two common uses for this test below.</p>
<div id="test-for-a-regression-relationship" class="section level3 hasAnchor" number="6.10.1">
<h3><span class="header-section-number">6.10.1</span> Test for a regression relationship<a href="inference.html#test-for-a-regression-relationship" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The most common test involving multiple parameters is to test whether <em>any</em> of the non-intercept regression
coefficients differ from zero. This test is known as the “test for a regression relationship”.</p>
<p>In this situation, the hypotheses to be tested may be stated as</p>
<p><span class="math display">\[
\begin{aligned}
&amp;H_0: E(Y \mid \mathbb{X}) = \beta_0 \\
&amp;H_a: E(Y\mid \mathbb{X}) = \beta_0 + X_1\beta_1 + \cdots + X_{p-1}\beta_{p-1}.
\end{aligned}
\]</span></p>
<p>Alternatively, we can state these hypotheses as</p>
<p><span class="math display">\[
\begin{aligned}
&amp;H_0: \beta_1 = \cdots = \beta_{p-1} = 0 \mid \beta_0 \in \mathbb{R} \\
&amp;H_a: \beta_1 \in \mathbb{R}  \text{ or } \ldots  \text{ or } \beta_{p-1}\in \mathbb{R} \mid \beta_0 \in \mathbb{R}.
\end{aligned}
\]</span></p>
<p>Notice that the RM in <span class="math inline">\(H_0\)</span> is a special case of the CM in <span class="math inline">\(H_a\)</span> with all the regression coefficients set equal to zero except for the intercept term. Notice that we specifically
conditioned our hypotheses on the intercept coefficient,
<span class="math inline">\(\beta_0\)</span>, being included in both models we are comparing.</p>
<p>The <span class="math inline">\(F\)</span> statistic in Equation <a href="inference.html#eq:f-stat-lh">(6.10)</a> used for
this test simplifies dramatically when performing a test for
a regression relationship.Using a bit of calculus or by
carefully using the OLS estimator of the regression
coefficients, it is possible to show that for the Reduced
Model that <span class="math inline">\(\hat{\beta}_0=\bar{Y}\)</span>. Thus, for the
<span class="math inline">\(RSS_{RM} = \sum_{i=1}^n (Y_i - \bar{Y})^2\)</span>, which is the
definition of the TSS defined in Chapter
<a href="linear-model-estimation.html#linear-model-estimation">3</a>! Then the numerator of our F
statistic becomes <span class="math inline">\(TSS - RSS_{CM}\)</span>, which is mathematically
equivalent to the regression sum of squares for the Complete
Model. The degrees of freedom of <span class="math inline">\(RSS_{RM} = n - 1\)</span>.
Similarly, the degrees of freedom of <span class="math inline">\(RSS_{CM} = n - p\)</span>.
Thus <span class="math inline">\(\mathrm{df}_{RM} - \mathrm{df}_{CM} = (n - 1) - (n - p) = p-1\)</span>. Thus,
Our F statistic for this test simplifies to</p>
<p><span class="math display">\[
F = \frac{SS_{reg}/(p-1)}{RSS_{CM}/(n-p)}= \frac{SS_{reg}/(p-1)}{\hat{\sigma}^2_{CM}},
\]</span>
where <span class="math inline">\(SS_{reg}\)</span> is for the CM.</p>
<p>Using the <code>penguins</code> data, let’s perform a test for a regression relationship for the model</p>
<p><span class="math display">\[
\begin{aligned}
&amp;E(\mathtt{bill\_length\_mm}\mid \mathtt{body\_mass\_g}, \mathtt{flipper\_length\_mm}) \\
&amp;=\beta_0+\beta_1 \mathtt{body\_mass\_g} + \beta_2 \mathtt{flipper\_length\_mm}.
\end{aligned}
\]</span></p>
<p>The fitted model is stored in <code>mlmod</code>.</p>
<p>We are testing</p>
<p><span class="math display">\[
\begin{aligned}
&amp;H_0: E(\mathtt{bill\_length\_mm}\mid \mathtt{body\_mass\_g}, \mathtt{flipper\_length\_mm}) = \beta_0 \\
&amp;H_a: E(\mathtt{bill\_length\_mm} \mid \mathtt{body\_mass\_g}, \mathtt{flipper\_length\_mm}) = \beta_0 + \beta_1 \mathtt{body\_mass\_g} + \beta_{2} \mathtt{flipper\_length\_mm}.
\end{aligned}
\]</span>
This can also be stated as</p>
<p><span class="math display">\[
\begin{aligned}
&amp;H_0: \beta_1 = \beta_2 = 0 \mid \beta_0 \in \mathbb{R} \\
&amp;H_a: \beta_1 \neq 0 \text{ or } \beta_2 \neq 0 \mid \beta_0 \in \mathbb{R}.
\end{aligned}
\]</span></p>
<p>We can get the necessary information for the test for a
regression relationship by using the <code>summary</code> function on
<code>mlmod</code>.</p>
<div class="sourceCode" id="cb174"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb174-1"><a href="inference.html#cb174-1" tabindex="-1"></a><span class="fu">summary</span>(mlmod)</span>
<span id="cb174-2"><a href="inference.html#cb174-2" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb174-3"><a href="inference.html#cb174-3" tabindex="-1"></a><span class="do">## Call:</span></span>
<span id="cb174-4"><a href="inference.html#cb174-4" tabindex="-1"></a><span class="do">## lm(formula = bill_length_mm ~ body_mass_g + flipper_length_mm, </span></span>
<span id="cb174-5"><a href="inference.html#cb174-5" tabindex="-1"></a><span class="do">##     data = penguins)</span></span>
<span id="cb174-6"><a href="inference.html#cb174-6" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb174-7"><a href="inference.html#cb174-7" tabindex="-1"></a><span class="do">## Residuals:</span></span>
<span id="cb174-8"><a href="inference.html#cb174-8" tabindex="-1"></a><span class="do">##     Min      1Q  Median      3Q     Max </span></span>
<span id="cb174-9"><a href="inference.html#cb174-9" tabindex="-1"></a><span class="do">## -8.8064 -2.5898 -0.7053  1.9911 18.8288 </span></span>
<span id="cb174-10"><a href="inference.html#cb174-10" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb174-11"><a href="inference.html#cb174-11" tabindex="-1"></a><span class="do">## Coefficients:</span></span>
<span id="cb174-12"><a href="inference.html#cb174-12" tabindex="-1"></a><span class="do">##                     Estimate Std. Error t value Pr(&gt;|t|)</span></span>
<span id="cb174-13"><a href="inference.html#cb174-13" tabindex="-1"></a><span class="do">## (Intercept)       -3.4366939  4.5805532  -0.750    0.454</span></span>
<span id="cb174-14"><a href="inference.html#cb174-14" tabindex="-1"></a><span class="do">## body_mass_g        0.0006622  0.0005672   1.168    0.244</span></span>
<span id="cb174-15"><a href="inference.html#cb174-15" tabindex="-1"></a><span class="do">## flipper_length_mm  0.2218655  0.0323484   6.859 3.31e-11</span></span>
<span id="cb174-16"><a href="inference.html#cb174-16" tabindex="-1"></a><span class="do">##                      </span></span>
<span id="cb174-17"><a href="inference.html#cb174-17" tabindex="-1"></a><span class="do">## (Intercept)          </span></span>
<span id="cb174-18"><a href="inference.html#cb174-18" tabindex="-1"></a><span class="do">## body_mass_g          </span></span>
<span id="cb174-19"><a href="inference.html#cb174-19" tabindex="-1"></a><span class="do">## flipper_length_mm ***</span></span>
<span id="cb174-20"><a href="inference.html#cb174-20" tabindex="-1"></a><span class="do">## ---</span></span>
<span id="cb174-21"><a href="inference.html#cb174-21" tabindex="-1"></a><span class="do">## Signif. codes:  </span></span>
<span id="cb174-22"><a href="inference.html#cb174-22" tabindex="-1"></a><span class="do">## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb174-23"><a href="inference.html#cb174-23" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb174-24"><a href="inference.html#cb174-24" tabindex="-1"></a><span class="do">## Residual standard error: 4.124 on 339 degrees of freedom</span></span>
<span id="cb174-25"><a href="inference.html#cb174-25" tabindex="-1"></a><span class="do">##   (2 observations deleted due to missingness)</span></span>
<span id="cb174-26"><a href="inference.html#cb174-26" tabindex="-1"></a><span class="do">## Multiple R-squared:  0.4329, Adjusted R-squared:  0.4295 </span></span>
<span id="cb174-27"><a href="inference.html#cb174-27" tabindex="-1"></a><span class="do">## F-statistic: 129.4 on 2 and 339 DF,  p-value: &lt; 2.2e-16</span></span></code></pre></div>
<p>The necessary information is in the last line of the
<code>summary</code> output.</p>
<pre><code>F-statistic: 129.4 on 2 and 339 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The test statistic for this test is 129.4 with a p-value
close to 0.</p>
<p>There is very strong evidence that at least one of the
regression coefficients for <code>body_mass_g</code> or
<code>flipper_length_mm</code> is non-zero in the regression model for
<code>bill_length_mm</code> that already includes an intercept.</p>
<p>Alternatively, the model regressing <code>bill_length_mm</code> on the
intercept, <code>body_mass_g</code>, and <code>flipper_length_mm</code> is
preferred to the model that has only an intercept.</p>
</div>
<div id="a-more-general-f-test" class="section level3 hasAnchor" number="6.10.2">
<h3><span class="header-section-number">6.10.2</span> A more general F test<a href="inference.html#a-more-general-f-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let us consider a more general F test where multiple
regression coefficients are set to zero. In general, the associated test statistic won’t simplify in any standard way.</p>
<p>We will illustrate the more general F test using the
<code>penguins</code> data.</p>
<p>Suppose we want to decide between the simple linear
regression model and the parallel lines model for the <code>penguins</code> data.</p>
<p>We want to test between</p>
<p><span class="math display">\[
\begin{aligned}
&amp;H_0: E(\mathtt{bill\_length\_mm} \mid \mathtt{body\_mass\_g}, \mathtt{species})\\
&amp;\qquad= \beta_{0} + \beta_1 \mathtt{body\_mass\_g} \\
&amp;H_a:  E(\mathtt{bill\_length\_mm} \mid \mathtt{body\_mass\_g}, \mathtt{species})\\
&amp;\qquad = \beta_{0} + \beta_1 \mathtt{body\_mass\_g} + \beta_2 D_C + \beta_3 D_G,
\end{aligned}
\]</span>
where <span class="math inline">\(D_C\)</span> and <span class="math inline">\(D_G\)</span> denote the indicator variables for the
<code>Chinstrap</code> and <code>Gentoo</code> level of penguin <code>species</code>.</p>
<p>Alternatively, we could state this as</p>
<p><span class="math display">\[
\begin{aligned}
&amp;H_0: \beta_2 = \beta_3 = 0 \mid \beta_0 \in \mathbb{R}, \beta_1 \in \mathbb{R}\\
&amp;H_a:  \beta_2 \neq 0 \text{ or } \beta_3 \neq 0 \mid \beta_0\in \mathbb{R}, \beta_1 \in \mathbb{R}.
\end{aligned}
\]</span></p>
<p>To perform our test, we must fit both models. We fit the simple linear regression model in the code below.</p>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb176-1"><a href="inference.html#cb176-1" tabindex="-1"></a>lmod <span class="ot">&lt;-</span> <span class="fu">lm</span>(bill_length_mm <span class="sc">~</span> body_mass_g, <span class="at">data =</span> penguins)</span>
<span id="cb176-2"><a href="inference.html#cb176-2" tabindex="-1"></a><span class="fu">coef</span>(lmod)</span>
<span id="cb176-3"><a href="inference.html#cb176-3" tabindex="-1"></a><span class="do">##  (Intercept)  body_mass_g </span></span>
<span id="cb176-4"><a href="inference.html#cb176-4" tabindex="-1"></a><span class="do">## 26.898872424  0.004051417</span></span></code></pre></div>
<p>We then fit the parallel lines model.</p>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb177-1"><a href="inference.html#cb177-1" tabindex="-1"></a>lmodp <span class="ot">&lt;-</span> <span class="fu">lm</span>(bill_length_mm <span class="sc">~</span> body_mass_g <span class="sc">+</span> species, <span class="at">data =</span> penguins)</span>
<span id="cb177-2"><a href="inference.html#cb177-2" tabindex="-1"></a><span class="fu">coef</span>(lmodp)</span>
<span id="cb177-3"><a href="inference.html#cb177-3" tabindex="-1"></a><span class="do">##      (Intercept)      body_mass_g speciesChinstrap </span></span>
<span id="cb177-4"><a href="inference.html#cb177-4" tabindex="-1"></a><span class="do">##     24.919470977      0.003748497      9.920884113 </span></span>
<span id="cb177-5"><a href="inference.html#cb177-5" tabindex="-1"></a><span class="do">##    speciesGentoo </span></span>
<span id="cb177-6"><a href="inference.html#cb177-6" tabindex="-1"></a><span class="do">##      3.557977539</span></span></code></pre></div>
<p>We use the <code>anova</code> function to get the test statistic and
p-value for our general F test. We supply the fitted <span class="math inline">\(RM\)</span> as
the first argument to the function and then the fitted <span class="math inline">\(CM\)</span>
as the second argument. We do that in the code below.</p>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb178-1"><a href="inference.html#cb178-1" tabindex="-1"></a><span class="fu">anova</span>(lmod, lmodp)</span>
<span id="cb178-2"><a href="inference.html#cb178-2" tabindex="-1"></a><span class="do">## Analysis of Variance Table</span></span>
<span id="cb178-3"><a href="inference.html#cb178-3" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb178-4"><a href="inference.html#cb178-4" tabindex="-1"></a><span class="do">## Model 1: bill_length_mm ~ body_mass_g</span></span>
<span id="cb178-5"><a href="inference.html#cb178-5" tabindex="-1"></a><span class="do">## Model 2: bill_length_mm ~ body_mass_g + species</span></span>
<span id="cb178-6"><a href="inference.html#cb178-6" tabindex="-1"></a><span class="do">##   Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    </span></span>
<span id="cb178-7"><a href="inference.html#cb178-7" tabindex="-1"></a><span class="do">## 1    340 6564.5                                  </span></span>
<span id="cb178-8"><a href="inference.html#cb178-8" tabindex="-1"></a><span class="do">## 2    338 1952.0  2    4612.5 399.35 &lt; 2.2e-16 ***</span></span>
<span id="cb178-9"><a href="inference.html#cb178-9" tabindex="-1"></a><span class="do">## ---</span></span>
<span id="cb178-10"><a href="inference.html#cb178-10" tabindex="-1"></a><span class="do">## Signif. codes:  </span></span>
<span id="cb178-11"><a href="inference.html#cb178-11" tabindex="-1"></a><span class="do">## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span></code></pre></div>
<p>The test statistic (<code>F</code>) is 399.35 and the associated
p-value (<code>Pr(&gt;F)</code>) is close to 0.</p>
<p>The is very strong evidence that the parallel lines model is preferred to the simple linear regression model for the <code>penguins</code> data.</p>
<p>We can do another test that compares the parallel lines
model to the separate lines model for the <code>penguins</code> data.</p>
<p>We want to choose between</p>
<p><span class="math display">\[
\begin{aligned}
&amp;H_0: E(\mathtt{bill\_length\_mm} \mid \mathtt{body\_mass\_g}, \mathtt{species}) \\
&amp;=\qquad \beta_{0} + \beta_1 \mathtt{body\_mass\_g} + \beta_2 D_C + \beta_3 D_G \\
&amp;H_a: E(\mathtt{bill\_length\_mm} \mid \mathtt{body\_mass\_g}, \mathtt{species}) \\
&amp;\qquad = \beta_{0} + \beta_1 \mathtt{body\_mass\_g} + \beta_2 D_C + \beta_3 D_G + \beta_4 \mathtt{body\_mass\_g} D_C + \beta_5 \mathtt{body\_mass\_g} D_G.
\end{aligned}
\]</span></p>
<p>Alternatively, we could state this as</p>
<p><span class="math display">\[
\begin{aligned}
&amp;H_0: \beta_4 = \beta_5 = 0 \mid \{\beta_0, \beta_1, \beta_2, \beta_3\} \in \mathbb{R}^4.\\
&amp;H_a: \beta_4 \neq 0 \text{ or } \beta_5 \neq 0 \mid \{\beta_0, \beta_1, \beta_2, \beta_3\} \in \mathbb{R}^4.
\end{aligned}
\]</span></p>
<p>We now fit the separate lines regression model to the
<code>penguins</code> data.</p>
<div class="sourceCode" id="cb179"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb179-1"><a href="inference.html#cb179-1" tabindex="-1"></a>lmods <span class="ot">&lt;-</span> <span class="fu">lm</span>(bill_length_mm <span class="sc">~</span> body_mass_g <span class="sc">+</span> species <span class="sc">+</span> body_mass_g<span class="sc">:</span>species,</span>
<span id="cb179-2"><a href="inference.html#cb179-2" tabindex="-1"></a>            <span class="at">data =</span> penguins)</span>
<span id="cb179-3"><a href="inference.html#cb179-3" tabindex="-1"></a><span class="fu">coef</span>(lmods)</span>
<span id="cb179-4"><a href="inference.html#cb179-4" tabindex="-1"></a><span class="do">##                  (Intercept)                  body_mass_g </span></span>
<span id="cb179-5"><a href="inference.html#cb179-5" tabindex="-1"></a><span class="do">##                26.9941391367                 0.0031878758 </span></span>
<span id="cb179-6"><a href="inference.html#cb179-6" tabindex="-1"></a><span class="do">##             speciesChinstrap                speciesGentoo </span></span>
<span id="cb179-7"><a href="inference.html#cb179-7" tabindex="-1"></a><span class="do">##                 5.1800537287                -0.2545906615 </span></span>
<span id="cb179-8"><a href="inference.html#cb179-8" tabindex="-1"></a><span class="do">## body_mass_g:speciesChinstrap    body_mass_g:speciesGentoo </span></span>
<span id="cb179-9"><a href="inference.html#cb179-9" tabindex="-1"></a><span class="do">##                 0.0012748183                 0.0009029956</span></span></code></pre></div>
<p>We once again use the <code>anova</code> function to get our associated
test statistic and p-value, as shown in the code below.</p>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="inference.html#cb180-1" tabindex="-1"></a><span class="fu">anova</span>(lmodp, lmods)</span>
<span id="cb180-2"><a href="inference.html#cb180-2" tabindex="-1"></a><span class="do">## Analysis of Variance Table</span></span>
<span id="cb180-3"><a href="inference.html#cb180-3" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb180-4"><a href="inference.html#cb180-4" tabindex="-1"></a><span class="do">## Model 1: bill_length_mm ~ body_mass_g + species</span></span>
<span id="cb180-5"><a href="inference.html#cb180-5" tabindex="-1"></a><span class="do">## Model 2: bill_length_mm ~ body_mass_g + species + body_mass_g:species</span></span>
<span id="cb180-6"><a href="inference.html#cb180-6" tabindex="-1"></a><span class="do">##   Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)</span></span>
<span id="cb180-7"><a href="inference.html#cb180-7" tabindex="-1"></a><span class="do">## 1    338 1952.0                           </span></span>
<span id="cb180-8"><a href="inference.html#cb180-8" tabindex="-1"></a><span class="do">## 2    336 1933.4  2    18.596 1.6159 0.2003</span></span></code></pre></div>
<p>The test statistic for this test is 1.62 with an associated
p-value of 0.20. It appears that for the model regressing <code>bill_length_mm</code> on <code>body_mass_g</code> and <code>species</code>, the parallel lines model is adequate and we do not need the additional complexity of the separate lines model.</p>
</div>
</div>
<div id="going-deeper-2" class="section level2 hasAnchor" number="6.11">
<h2><span class="header-section-number">6.11</span> Going deeper<a href="inference.html#going-deeper-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="manual-t-cis" class="section level3 hasAnchor" number="6.11.1">
<h3><span class="header-section-number">6.11.1</span> Manual calculation of the standard <span class="math inline">\(t\)</span>-based confidence interval for a regression coefficient<a href="inference.html#manual-t-cis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider the summary of the fitted linear model below, which
summarizes a first-order linear model fit to the <code>penguins</code>
data earlier in this chapter.</p>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb181-1"><a href="inference.html#cb181-1" tabindex="-1"></a><span class="fu">summary</span>(mlmod)</span>
<span id="cb181-2"><a href="inference.html#cb181-2" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb181-3"><a href="inference.html#cb181-3" tabindex="-1"></a><span class="do">## Call:</span></span>
<span id="cb181-4"><a href="inference.html#cb181-4" tabindex="-1"></a><span class="do">## lm(formula = bill_length_mm ~ body_mass_g + flipper_length_mm, </span></span>
<span id="cb181-5"><a href="inference.html#cb181-5" tabindex="-1"></a><span class="do">##     data = penguins)</span></span>
<span id="cb181-6"><a href="inference.html#cb181-6" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb181-7"><a href="inference.html#cb181-7" tabindex="-1"></a><span class="do">## Residuals:</span></span>
<span id="cb181-8"><a href="inference.html#cb181-8" tabindex="-1"></a><span class="do">##     Min      1Q  Median      3Q     Max </span></span>
<span id="cb181-9"><a href="inference.html#cb181-9" tabindex="-1"></a><span class="do">## -8.8064 -2.5898 -0.7053  1.9911 18.8288 </span></span>
<span id="cb181-10"><a href="inference.html#cb181-10" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb181-11"><a href="inference.html#cb181-11" tabindex="-1"></a><span class="do">## Coefficients:</span></span>
<span id="cb181-12"><a href="inference.html#cb181-12" tabindex="-1"></a><span class="do">##                     Estimate Std. Error t value Pr(&gt;|t|)</span></span>
<span id="cb181-13"><a href="inference.html#cb181-13" tabindex="-1"></a><span class="do">## (Intercept)       -3.4366939  4.5805532  -0.750    0.454</span></span>
<span id="cb181-14"><a href="inference.html#cb181-14" tabindex="-1"></a><span class="do">## body_mass_g        0.0006622  0.0005672   1.168    0.244</span></span>
<span id="cb181-15"><a href="inference.html#cb181-15" tabindex="-1"></a><span class="do">## flipper_length_mm  0.2218655  0.0323484   6.859 3.31e-11</span></span>
<span id="cb181-16"><a href="inference.html#cb181-16" tabindex="-1"></a><span class="do">##                      </span></span>
<span id="cb181-17"><a href="inference.html#cb181-17" tabindex="-1"></a><span class="do">## (Intercept)          </span></span>
<span id="cb181-18"><a href="inference.html#cb181-18" tabindex="-1"></a><span class="do">## body_mass_g          </span></span>
<span id="cb181-19"><a href="inference.html#cb181-19" tabindex="-1"></a><span class="do">## flipper_length_mm ***</span></span>
<span id="cb181-20"><a href="inference.html#cb181-20" tabindex="-1"></a><span class="do">## ---</span></span>
<span id="cb181-21"><a href="inference.html#cb181-21" tabindex="-1"></a><span class="do">## Signif. codes:  </span></span>
<span id="cb181-22"><a href="inference.html#cb181-22" tabindex="-1"></a><span class="do">## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb181-23"><a href="inference.html#cb181-23" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb181-24"><a href="inference.html#cb181-24" tabindex="-1"></a><span class="do">## Residual standard error: 4.124 on 339 degrees of freedom</span></span>
<span id="cb181-25"><a href="inference.html#cb181-25" tabindex="-1"></a><span class="do">##   (2 observations deleted due to missingness)</span></span>
<span id="cb181-26"><a href="inference.html#cb181-26" tabindex="-1"></a><span class="do">## Multiple R-squared:  0.4329, Adjusted R-squared:  0.4295 </span></span>
<span id="cb181-27"><a href="inference.html#cb181-27" tabindex="-1"></a><span class="do">## F-statistic: 129.4 on 2 and 339 DF,  p-value: &lt; 2.2e-16</span></span></code></pre></div>
<p>If we want to manually produce 95% confidence intervals for
the true regression coefficients for this model using
Equation <a href="inference.html#eq:t-ci-betas">(6.4)</a>, then we need to acquire some
basic information. We need:</p>
<ul>
<li>the estimated regression coefficients</li>
<li>the degrees of freedom for the fitted model <span class="math inline">\(n-p\)</span></li>
<li>the <span class="math inline">\(1-\alpha/2\)</span> quantile of a <span class="math inline">\(t\)</span> random variable with
<span class="math inline">\(n-p\)</span> degrees of freedom</li>
<li>the estimated standard error of the estimated regression
coefficients.</li>
</ul>
<p>The estimated regression coefficients can be extracted from
our fitted model, <code>mlmod</code>, using the <code>coef</code> function. We
extract and print the estimated coefficients using the code
below while simultaneously assigning the vector the name
<code>betahats</code>.</p>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb182-1"><a href="inference.html#cb182-1" tabindex="-1"></a><span class="co"># extract estimated coefficients from mlmod</span></span>
<span id="cb182-2"><a href="inference.html#cb182-2" tabindex="-1"></a>(betahats <span class="ot">&lt;-</span> <span class="fu">coef</span>(mlmod))</span>
<span id="cb182-3"><a href="inference.html#cb182-3" tabindex="-1"></a><span class="do">##       (Intercept)       body_mass_g flipper_length_mm </span></span>
<span id="cb182-4"><a href="inference.html#cb182-4" tabindex="-1"></a><span class="do">##     -3.4366939266      0.0006622186      0.2218654584</span></span></code></pre></div>
<p>The degrees of freedom <span class="math inline">\(n-p\)</span> is referred to as the residual
degrees of freedom and can be obtained by using the
<code>df.residual</code> function on the fitted model. Using the code
below, we see that the residual degrees of freedom is 339
(this information was also in the summary of the fitted
model).</p>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb183-1"><a href="inference.html#cb183-1" tabindex="-1"></a><span class="fu">df.residual</span>(mlmod)</span>
<span id="cb183-2"><a href="inference.html#cb183-2" tabindex="-1"></a><span class="do">## [1] 339</span></span></code></pre></div>
<p>To construct a 95% confidence interval for our coefficients,
we need to determine the <span class="math inline">\(0.975\)</span> quantile of a <span class="math inline">\(t\)</span> random
variable with 339 degrees of freedom. This can be found
using the <code>qt</code> function, as is done in the code below. We
assign this value the name <code>mult</code>. Notice that value is a
bit above 1.96, which is the value often seen in
introductory statistics courses for confidence intervals
based on the standard normal distribution (<span class="math inline">\(\mathsf{N}(0,1)\)</span>
distribution).</p>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb184-1"><a href="inference.html#cb184-1" tabindex="-1"></a>(mult <span class="ot">&lt;-</span> <span class="fu">qt</span>(<span class="fl">0.975</span>, <span class="at">df =</span> <span class="dv">339</span>))</span>
<span id="cb184-2"><a href="inference.html#cb184-2" tabindex="-1"></a><span class="do">## [1] 1.966986</span></span></code></pre></div>
<p>The estimated standard errors of each coefficient are shown
in the summary of the fitted model. They are (approximately)
4.58, 0.00057, and 0.032 and can be obtained by extracting
the 2nd column of the <code>coefficients</code> element produced by the
<code>summary</code> function.</p>
<div class="sourceCode" id="cb185"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb185-1"><a href="inference.html#cb185-1" tabindex="-1"></a>(sehats <span class="ot">&lt;-</span> <span class="fu">summary</span>(mlmod)<span class="sc">$</span>coefficients[,<span class="dv">2</span>])</span>
<span id="cb185-2"><a href="inference.html#cb185-2" tabindex="-1"></a><span class="do">##       (Intercept)       body_mass_g flipper_length_mm </span></span>
<span id="cb185-3"><a href="inference.html#cb185-3" tabindex="-1"></a><span class="do">##      4.5805531903      0.0005672075      0.0323484492</span></span></code></pre></div>
<p>A alternative approach is to use 3 step process below:</p>
<ol style="list-style-type: decimal">
<li>Use the <code>vcov</code> function to obtain the estimated variance
matrix of <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span>, i.e.,
<span class="math inline">\(\hat{\mathrm{var}}(\hat{\boldsymbol{\beta}})\)</span>.</li>
<li>Use the <code>diag</code> function to extract the diagonal elements
of this matrix, which gives us
<span class="math inline">\(\hat{\mathrm{var}}(\hat{\beta}_0), \hat{\mathrm{var}}(\hat{\beta}_1), \ldots, \hat{\mathrm{var}}(\hat{\beta}_{p-1})\)</span>.</li>
<li>Use the <code>sqrt</code> function to calculate the estimated
standard errors from the estimated variances of the
estimated coefficients.</li>
</ol>
<p>We use this process in the code below, which returns the
same estimated standard errors we previously obtained.</p>
<div class="sourceCode" id="cb186"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb186-1"><a href="inference.html#cb186-1" tabindex="-1"></a><span class="co"># 2nd approach to obtaining estimated standard errors</span></span>
<span id="cb186-2"><a href="inference.html#cb186-2" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">diag</span>(<span class="fu">vcov</span>(mlmod)))</span>
<span id="cb186-3"><a href="inference.html#cb186-3" tabindex="-1"></a><span class="do">##       (Intercept)       body_mass_g flipper_length_mm </span></span>
<span id="cb186-4"><a href="inference.html#cb186-4" tabindex="-1"></a><span class="do">##      4.5805531903      0.0005672075      0.0323484492</span></span></code></pre></div>
<p>Using the estimated coefficients (<code>betahats</code>), the
appropriate quantile of the <span class="math inline">\(t\)</span> distribution (<code>mult</code>), and
the estimated standard errors (<code>sehats</code>), we can manually
produce the standard t-based confidence intervals using the
code below.</p>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb187-1"><a href="inference.html#cb187-1" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">lb =</span> betahats <span class="sc">-</span> mult <span class="sc">*</span> sehats,</span>
<span id="cb187-2"><a href="inference.html#cb187-2" tabindex="-1"></a>           <span class="at">ub =</span> betahats <span class="sc">+</span> mult <span class="sc">*</span> sehats)</span>
<span id="cb187-3"><a href="inference.html#cb187-3" tabindex="-1"></a><span class="do">##                              lb          ub</span></span>
<span id="cb187-4"><a href="inference.html#cb187-4" tabindex="-1"></a><span class="do">## (Intercept)       -1.244658e+01 5.573192182</span></span>
<span id="cb187-5"><a href="inference.html#cb187-5" tabindex="-1"></a><span class="do">## body_mass_g       -4.534709e-04 0.001777908</span></span>
<span id="cb187-6"><a href="inference.html#cb187-6" tabindex="-1"></a><span class="do">## flipper_length_mm  1.582365e-01 0.285494420</span></span></code></pre></div>
</div>
<div id="mean-response-calculations" class="section level3 hasAnchor" number="6.11.2">
<h3><span class="header-section-number">6.11.2</span> Details about estimation of the mean response<a href="inference.html#mean-response-calculations" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider the estimated mean response for a specific
combination of regressor values, denoted by <span class="math inline">\(\mathbf{x}_0\)</span>,
so that
<span class="math display">\[\hat{E}(Y\mid \mathbf{x}_0)=\mathbf{x}_0^T\hat{\boldsymbol{\beta}}.\]</span></p>
<p>Using some of the matrix-related results from Appendix
<a href="prob-review.html#prob-review">B</a> and the result in Equation
<a href="inference.html#eq:prop-betahat">(6.3)</a>, we can determine that
<span class="math display" id="eq:var-est-mean-response">\[
\begin{aligned}
\mathrm{var}\left(\hat{E}(Y \mid \mathbf{x}_0)\right) &amp;= \mathrm{var}(\mathbf{x}_0^T \hat{\boldsymbol{\beta}}) \\
&amp;= \mathbf{x}_0^T \mathrm{var}(\hat{\boldsymbol{\beta}})\mathbf{x}_0\\
&amp;= \sigma^2 \mathbf{x}_0^T (\mathbf{X}^T \mathbf{X})^{-1}\mathbf{x}_0.
\end{aligned}
\tag{6.11}
\]</span>
To get the simplest expression for the confidence
interval for <span class="math inline">\(E(Y\mid\mathbf{x}_0)\)</span>, we have to make a
number of connections that are often glossed over. We
discuss them explicitly. Since the error variance,
<span class="math inline">\(\sigma^2\)</span>, in Equation <a href="inference.html#eq:var-est-mean-response">(6.11)</a>
isn’t known, we replace it with the typical estimator
<span class="math inline">\(\hat{\sigma}^2=RSS/(n-p)\)</span> to get
<span class="math display" id="eq:est-var-mean">\[
\hat{\mathrm{var}}\left(\hat{E}(Y\mid\mathbf{x}_0)\right)=\hat{\sigma}^2 \mathbf{x}_0^T (\mathbf{X}^T \mathbf{X})^{-1}\mathbf{x}_0. \tag{6.12}
\]</span></p>
<p>The standard error of an estimator is the standard deviation
of the estimator’s variance, so we have
<span class="math inline">\(\mathrm{se}\left(\hat{E}(Y\mid\mathbf{x}_0)\right)=\sqrt{\mathrm{var}\left(\hat{E}(Y\mid \mathbf{x}_0)\right)}\)</span>.
Similarly, we have that the estimated standard error for
<span class="math inline">\(\hat{E}(Y\mid \mathbf{x}_0)\)</span> is
<span class="math inline">\(\hat{\mathrm{se}}\left(\hat{E}(Y\mid\mathbf{x}_0)\right)=\sqrt{\hat{\mathrm{var}}\left(\hat{E}(Y\mid \mathbf{x}_0)\right)}\)</span>.
Taking the square root of Equation <a href="inference.html#eq:est-var-mean">(6.12)</a>,
we see that
<span class="math display">\[
\hat{\mathrm{se}}\left(\hat{E}(Y\mid \mathbf{x}_0)\right)=\hat{\sigma} \sqrt{\mathbf{x}_0^T (\mathbf{X}^T \mathbf{X})^{-1}\mathbf{x}_0}.
\]</span></p>
<p>Additionally, since <span class="math inline">\(E(Y\mid \mathbf{x}_0)\)</span> is an (unknown)
constant, we also have that
<span class="math display">\[\mathrm{var}\left(E(Y\mid \mathbf{x}_0)-\hat{E}(Y\mid \mathbf{x}_0)\right)=\mathrm{var}\left(\hat{E}(Y\mid \mathbf{x}_0)\right).
\]</span>
If we divide the estimation error of the mean response,
i.e., <span class="math inline">\(E(Y\mid \mathbf{x}_0)-\hat{E}(Y\mid \mathbf{x}_0)\)</span>,
by its estimated standard deviation, then we obtain a
pivotal quantity. More specifically, we have
<span class="math display">\[
\frac{E(Y\mid \mathbf{x}_0)-\hat{E}(Y\mid \mathbf{x}_0)}{\sqrt{\hat{\mathrm{var}}\left(E(Y\mid \mathbf{x}_0)-\hat{E}(Y\mid \mathbf{x}_0)\right)}} = \frac{E(Y\mid \mathbf{x}_0)- \mathbf{x}_0 \hat{\boldsymbol{\beta}}}{ \hat{\mathrm{se}}(\mathbf{x}_0\hat{\boldsymbol{\beta}})}\sim t_{n-p}.
\]</span></p>
</div>
<div id="manual-calc-ci-mean-response" class="section level3 hasAnchor" number="6.11.3">
<h3><span class="header-section-number">6.11.3</span> Manual calculation of confidence intervals for the mean response<a href="inference.html#manual-calc-ci-mean-response" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We discuss manual computation of the estimated mean response
and associated confidence interval for a particular
combination of regressor values based on the <code>penguins</code>
example discussed in Section
<a href="inference.html#parametric-ci-mean-response">6.7</a>.</p>
<p>Specifically, we estimate the mean response for the fitted
parallel lines model given by<span class="math display">\[
\begin{aligned}
&amp;\hat{E}(\mathtt{bill\_length\_mm} \mid \mathtt{body\_mass\_g}, \mathtt{species})\\
&amp;= 24.92 + 0.004 \mathtt{body\_mass\_g} + 9.92 D_C + 3.56 D_G,
\end{aligned}
\]</span> where <span class="math inline">\(D_C\)</span> and <span class="math inline">\(D_G\)</span> denote the indicator variables for
the <code>Chinstrap</code> and <code>Gentoo</code> levels of the <code>species</code>
variable. This fitted model is stored in <code>lmodp</code>. The
estimated coefficients are shown in the code below.</p>
<div class="sourceCode" id="cb188"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb188-1"><a href="inference.html#cb188-1" tabindex="-1"></a><span class="fu">coef</span>(lmodp)</span>
<span id="cb188-2"><a href="inference.html#cb188-2" tabindex="-1"></a><span class="do">##      (Intercept)      body_mass_g speciesChinstrap </span></span>
<span id="cb188-3"><a href="inference.html#cb188-3" tabindex="-1"></a><span class="do">##     24.919470977      0.003748497      9.920884113 </span></span>
<span id="cb188-4"><a href="inference.html#cb188-4" tabindex="-1"></a><span class="do">##    speciesGentoo </span></span>
<span id="cb188-5"><a href="inference.html#cb188-5" tabindex="-1"></a><span class="do">##      3.557977539</span></span></code></pre></div>
<p>We want to estimate the mean response for the following
combination of predictors stored in the <code>newpenguins</code> data
frame, which is printed in the code below.</p>
<div class="sourceCode" id="cb189"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb189-1"><a href="inference.html#cb189-1" tabindex="-1"></a><span class="co"># mean body_mass_g of each species</span></span>
<span id="cb189-2"><a href="inference.html#cb189-2" tabindex="-1"></a>newpenguins</span>
<span id="cb189-3"><a href="inference.html#cb189-3" tabindex="-1"></a><span class="do">## # A tibble: 3 × 2</span></span>
<span id="cb189-4"><a href="inference.html#cb189-4" tabindex="-1"></a><span class="do">##   species   body_mass_g</span></span>
<span id="cb189-5"><a href="inference.html#cb189-5" tabindex="-1"></a><span class="do">##   &lt;fct&gt;           &lt;dbl&gt;</span></span>
<span id="cb189-6"><a href="inference.html#cb189-6" tabindex="-1"></a><span class="do">## 1 Adelie          3701.</span></span>
<span id="cb189-7"><a href="inference.html#cb189-7" tabindex="-1"></a><span class="do">## 2 Chinstrap       3733.</span></span>
<span id="cb189-8"><a href="inference.html#cb189-8" tabindex="-1"></a><span class="do">## 3 Gentoo          5076.</span></span></code></pre></div>
<p>We want to use the <code>newpenguins</code> data frame to generate the
matrix of regressors used to estimate the associated mean
responses. We can create the matrix of regressors using the
<code>model.matrix</code> function. The main arguments of
<code>model.matrix</code> are:</p>
<ul>
<li><code>object</code>: an object of the appropriate class. In our
case, it is a formula or fitted model.</li>
<li><code>data</code>: a data frame with the predictors needed to
construct the matrix.</li>
</ul>
<p>We need only the right side of the formula used to fit the
model in <code>lmodp</code> to create our matrix of regressor values.
We can use the <code>formula</code> function to extract the formula
used to fit <code>lmodp</code>. We then use <code>model.matrix</code> to create
the matrix of regressor by values needed for estimating the
mean. The matrix produced by <code>model.matrix</code>, <code>X0</code>, includes
a column for the intercept term and the indicator variables
in <code>lmodp</code>.</p>
<div class="sourceCode" id="cb190"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb190-1"><a href="inference.html#cb190-1" tabindex="-1"></a><span class="co"># determine formula used to fit lmodp</span></span>
<span id="cb190-2"><a href="inference.html#cb190-2" tabindex="-1"></a><span class="fu">formula</span>(lmodp)</span>
<span id="cb190-3"><a href="inference.html#cb190-3" tabindex="-1"></a><span class="do">## bill_length_mm ~ body_mass_g + species</span></span>
<span id="cb190-4"><a href="inference.html#cb190-4" tabindex="-1"></a><span class="co"># create matrix of regressor values from newpenguins</span></span>
<span id="cb190-5"><a href="inference.html#cb190-5" tabindex="-1"></a>(X0 <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(<span class="sc">~</span> body_mass_g <span class="sc">+</span> species, <span class="at">data =</span> newpenguins))</span>
<span id="cb190-6"><a href="inference.html#cb190-6" tabindex="-1"></a><span class="do">##   (Intercept) body_mass_g speciesChinstrap speciesGentoo</span></span>
<span id="cb190-7"><a href="inference.html#cb190-7" tabindex="-1"></a><span class="do">## 1           1    3700.662                0             0</span></span>
<span id="cb190-8"><a href="inference.html#cb190-8" tabindex="-1"></a><span class="do">## 2           1    3733.088                1             0</span></span>
<span id="cb190-9"><a href="inference.html#cb190-9" tabindex="-1"></a><span class="do">## 3           1    5076.016                0             1</span></span>
<span id="cb190-10"><a href="inference.html#cb190-10" tabindex="-1"></a><span class="do">## attr(,&quot;assign&quot;)</span></span>
<span id="cb190-11"><a href="inference.html#cb190-11" tabindex="-1"></a><span class="do">## [1] 0 1 2 2</span></span>
<span id="cb190-12"><a href="inference.html#cb190-12" tabindex="-1"></a><span class="do">## attr(,&quot;contrasts&quot;)</span></span>
<span id="cb190-13"><a href="inference.html#cb190-13" tabindex="-1"></a><span class="do">## attr(,&quot;contrasts&quot;)$species</span></span>
<span id="cb190-14"><a href="inference.html#cb190-14" tabindex="-1"></a><span class="do">## [1] &quot;contr.treatment&quot;</span></span></code></pre></div>
<p>We can obtain the estimated mean by taking the product of
<code>X0</code> and the estimated coefficients for <code>lmodp</code>. We assign
the estimated mean responses the name <code>est_means</code>.</p>
<div class="sourceCode" id="cb191"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb191-1"><a href="inference.html#cb191-1" tabindex="-1"></a>(est_means <span class="ot">&lt;-</span> X0 <span class="sc">%*%</span> <span class="fu">coef</span>(lmodp))</span>
<span id="cb191-2"><a href="inference.html#cb191-2" tabindex="-1"></a><span class="do">##       [,1]</span></span>
<span id="cb191-3"><a href="inference.html#cb191-3" tabindex="-1"></a><span class="do">## 1 38.79139</span></span>
<span id="cb191-4"><a href="inference.html#cb191-4" tabindex="-1"></a><span class="do">## 2 48.83382</span></span>
<span id="cb191-5"><a href="inference.html#cb191-5" tabindex="-1"></a><span class="do">## 3 47.50488</span></span></code></pre></div>
<p>We now use Equation <a href="inference.html#eq:sehat-est-mean">(6.5)</a> to get the
estimated standard error of each estimated mean response.
First, we use <code>model.matrix</code> to extract the original matrix
of regressors, <span class="math inline">\(\mathbf{X}\)</span>, from the fitted model <code>lmodp</code>.
The <code>sigma</code> function is used to extract <span class="math inline">\(\hat{\sigma}\)</span> from
<code>lmodp</code>. Each <em>row</em> of <code>X0</code> contains a particular instance
regressor values. In the code below, we extract each row of
<code>X0</code>, and then use Equation <a href="inference.html#eq:sehat-est-mean">(6.5)</a> to
compute the estimated standard error associated with each
estimated mean response; these are assigned the names <code>se1</code>,
<code>se2</code>, and <code>se3</code>. That approach isn’t scalable, so we
provide a scalable version of these computations that is
assigned the name <code>sehat</code>.</p>
<div class="sourceCode" id="cb192"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb192-1"><a href="inference.html#cb192-1" tabindex="-1"></a><span class="co"># original matrix of regressors</span></span>
<span id="cb192-2"><a href="inference.html#cb192-2" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(lmodp)</span>
<span id="cb192-3"><a href="inference.html#cb192-3" tabindex="-1"></a>sigmahat <span class="ot">&lt;-</span> <span class="fu">sigma</span>(lmodp)</span>
<span id="cb192-4"><a href="inference.html#cb192-4" tabindex="-1"></a><span class="co"># compute estimated standard error for each estimated mean response</span></span>
<span id="cb192-5"><a href="inference.html#cb192-5" tabindex="-1"></a><span class="co"># crossprod(X) = t(X) %*% X</span></span>
<span id="cb192-6"><a href="inference.html#cb192-6" tabindex="-1"></a>(sehat1 <span class="ot">&lt;-</span> sigmahat <span class="sc">*</span> <span class="fu">sqrt</span>(<span class="fu">t</span>(X0[<span class="dv">1</span>,]) <span class="sc">%*%</span> <span class="fu">solve</span>(<span class="fu">crossprod</span>(X), X0[<span class="dv">1</span>,])))</span>
<span id="cb192-7"><a href="inference.html#cb192-7" tabindex="-1"></a><span class="do">##           [,1]</span></span>
<span id="cb192-8"><a href="inference.html#cb192-8" tabindex="-1"></a><span class="do">## [1,] 0.1955643</span></span>
<span id="cb192-9"><a href="inference.html#cb192-9" tabindex="-1"></a>(sehat2 <span class="ot">&lt;-</span> sigmahat <span class="sc">*</span> <span class="fu">sqrt</span>(<span class="fu">t</span>(X0[<span class="dv">2</span>,]) <span class="sc">%*%</span> <span class="fu">solve</span>(<span class="fu">crossprod</span>(X), X0[<span class="dv">2</span>,])))</span>
<span id="cb192-10"><a href="inference.html#cb192-10" tabindex="-1"></a><span class="do">##           [,1]</span></span>
<span id="cb192-11"><a href="inference.html#cb192-11" tabindex="-1"></a><span class="do">## [1,] 0.2914228</span></span>
<span id="cb192-12"><a href="inference.html#cb192-12" tabindex="-1"></a>(sehat3 <span class="ot">&lt;-</span> sigmahat <span class="sc">*</span> <span class="fu">sqrt</span>(<span class="fu">t</span>(X0[<span class="dv">3</span>,]) <span class="sc">%*%</span> <span class="fu">solve</span>(<span class="fu">crossprod</span>(X), X0[<span class="dv">3</span>,])))</span>
<span id="cb192-13"><a href="inference.html#cb192-13" tabindex="-1"></a><span class="do">##           [,1]</span></span>
<span id="cb192-14"><a href="inference.html#cb192-14" tabindex="-1"></a><span class="do">## [1,] 0.2166833</span></span>
<span id="cb192-15"><a href="inference.html#cb192-15" tabindex="-1"></a><span class="co"># scalable computation of estimated standard errors</span></span>
<span id="cb192-16"><a href="inference.html#cb192-16" tabindex="-1"></a>(sehat <span class="ot">&lt;-</span> sigmahat <span class="sc">*</span> <span class="fu">sqrt</span>(<span class="fu">diag</span>(X0 <span class="sc">%*%</span> <span class="fu">solve</span>(<span class="fu">crossprod</span>(X), <span class="fu">t</span>(X0)))))</span>
<span id="cb192-17"><a href="inference.html#cb192-17" tabindex="-1"></a><span class="do">##         1         2         3 </span></span>
<span id="cb192-18"><a href="inference.html#cb192-18" tabindex="-1"></a><span class="do">## 0.1955643 0.2914228 0.2166833</span></span></code></pre></div>
<p>To finish the computation of our confidence intervals, we
determine the correct multiplier, <span class="math inline">\(t_{n-p}^{\alpha/2}\)</span>. For
a 98% confidence interval, <span class="math inline">\(\alpha = 0.02\)</span> and
<span class="math inline">\(\alpha/2 = 0.01\)</span>. The degrees of freedom, <span class="math inline">\(n-p\)</span>, is 338 (as
shown in the code below). So the multiplier can be
represented as <span class="math inline">\(t_{338}^{0.01}\)</span>, which is the <span class="math inline">\(0.99\)</span>
quantile of a <span class="math inline">\(t\)</span> distribution with 338 degrees of freedom.
We provide this information to the <code>qt</code> function, which
provides the quantiles of a <span class="math inline">\(t\)</span> distribution, using the code
below to get the correct multiplier.</p>
<div class="sourceCode" id="cb193"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb193-1"><a href="inference.html#cb193-1" tabindex="-1"></a><span class="co"># degrees of freedom, n-p</span></span>
<span id="cb193-2"><a href="inference.html#cb193-2" tabindex="-1"></a><span class="fu">df.residual</span>(lmodp)</span>
<span id="cb193-3"><a href="inference.html#cb193-3" tabindex="-1"></a><span class="do">## [1] 338</span></span>
<span id="cb193-4"><a href="inference.html#cb193-4" tabindex="-1"></a><span class="co"># multiplier for confidence interval</span></span>
<span id="cb193-5"><a href="inference.html#cb193-5" tabindex="-1"></a>(mult <span class="ot">&lt;-</span> <span class="fu">qt</span>(<span class="fl">0.99</span>, <span class="at">df =</span> <span class="fu">df.residual</span>(lmodp)))</span>
<span id="cb193-6"><a href="inference.html#cb193-6" tabindex="-1"></a><span class="do">## [1] 2.337431</span></span></code></pre></div>
<p>Thus, our 98% confidence intervals for each mean response
can be computed using the code below, which matches the
results we obtained in Section
<a href="inference.html#parametric-ci-mean-response">6.7</a>.</p>
<div class="sourceCode" id="cb194"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb194-1"><a href="inference.html#cb194-1" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">lb =</span> est_means <span class="sc">-</span> mult <span class="sc">*</span> sehat,</span>
<span id="cb194-2"><a href="inference.html#cb194-2" tabindex="-1"></a>           <span class="at">ub =</span> est_means <span class="sc">+</span> mult <span class="sc">*</span> sehat)</span>
<span id="cb194-3"><a href="inference.html#cb194-3" tabindex="-1"></a><span class="do">##         lb       ub</span></span>
<span id="cb194-4"><a href="inference.html#cb194-4" tabindex="-1"></a><span class="do">## 1 38.33427 39.24851</span></span>
<span id="cb194-5"><a href="inference.html#cb194-5" tabindex="-1"></a><span class="do">## 2 48.15264 49.51500</span></span>
<span id="cb194-6"><a href="inference.html#cb194-6" tabindex="-1"></a><span class="do">## 3 46.99840 48.01136</span></span></code></pre></div>
</div>
<div id="new-response-pi-calculations" class="section level3 hasAnchor" number="6.11.4">
<h3><span class="header-section-number">6.11.4</span> Details about prediction interval for a new response<a href="inference.html#new-response-pi-calculations" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We want to predict the value of a new response for a
specific combination of regressor values, <span class="math inline">\(\mathbf{x}_0\)</span>.
The value of the new response is denoted by
<span class="math inline">\(Y(\mathbf{x}_0)\)</span> and its prediction by
<span class="math inline">\(\hat{Y}(\mathbf{x}_0)\)</span>.</p>
<p>In Section <a href="inference.html#pi-new-response">6.8</a>, we briefly discussed that
the new response may be written as
<span class="math display">\[
Y(\mathbf{x}_0) = E(Y \mid \mathbf{x}_0) + \epsilon(\mathbf{x}_0),
\]</span>
and that the predicted new response, under our standard
assumptions, is given by
<span class="math display">\[
\hat{Y}(\mathbf{x}_0)=\mathbf{x}_0^T\hat{\boldsymbol{\beta}}.
\]</span></p>
<p>Using these relationships, we can determine that the
variance of the prediction error for a new response is given
by
<span class="math display" id="eq:var-pred-error1">\[
\begin{aligned}
\mathrm{var}\left(Y(\mathbf{x}_0)-\hat{Y}(\mathbf{x}_0)\right) &amp;= \mathrm{var}(Y(\mathbf{x}_0)-\mathbf{x}_0^T \hat{\boldsymbol{\beta}}) \\
&amp;= \mathrm{var}(\mathbf{x}_0^T\boldsymbol{\beta} + \epsilon(\mathbf{x}_0)-\mathbf{x}_0^T \hat{\boldsymbol{\beta}}) \\
\end{aligned}
\tag{6.13}
\]</span></p>
<p>Recall from Appendix <a href="prob-review.html#prob-review">B</a> that the variance of
a constant plus a random variable is equal to the variance
of the random variable (since a constant doesn’t vary!).
Thus, Equation <a href="inference.html#eq:var-pred-error1">(6.13)</a> simplifies to
<span class="math display" id="eq:var-pred-error2">\[
\mathrm{var}\left(Y(\mathbf{x}_0)-\hat{Y}(\mathbf{x}_0)\right) = \mathrm{var}(\epsilon(\mathbf{x}_0)-\mathbf{x}_0^T \hat{\boldsymbol{\beta}}). \tag{6.14}
\]</span>
Using results from Appendix <a href="prob-review.html#prob-review">B</a> related to
the variance of a sum of random variables, we have that
<span class="math display" id="eq:var-pred-error3">\[
\begin{aligned}
&amp;\mathrm{var}\left(Y(\mathbf{x}_0)-\hat{Y}(\mathbf{x}_0)\right) \\
&amp;= \mathrm{var}(\epsilon(\mathbf{x}_0)-\mathbf{x}_0^T \hat{\boldsymbol{\beta}}) \\
&amp;= \mathrm{var}\left(\epsilon(\mathbf{x}_0)\right)+\mathrm{var}(-\mathbf{x}_0^T \hat{\boldsymbol{\beta}}) + 2\mathrm{cov}\left(\epsilon(\mathbf{x}_0), -\mathbf{x}_0^T \hat{\boldsymbol{\beta}}\right) \\
&amp;= \mathrm{var}\left(\epsilon(\mathbf{x}_0)\right)+(-1)^2\mathrm{var}(\mathbf{x}_0^T \hat{\boldsymbol{\beta}}) - 2\mathrm{cov}\left(\epsilon(\mathbf{x}_0), \mathbf{x}_0^T \hat{\boldsymbol{\beta}}\right) \\
&amp;= \mathrm{var}\left(\epsilon(\mathbf{x}_0)\right)+\mathrm{var}(\mathbf{x}_0^T \hat{\boldsymbol{\beta}}) - 2\mathrm{cov}\left(\epsilon(\mathbf{x}_0), \mathbf{x}_0^T \hat{\boldsymbol{\beta}}\right).
\end{aligned}
\tag{6.15}
\]</span></p>
<p>The covariance term in the final line of Equation
<a href="inference.html#eq:var-pred-error3">(6.15)</a> is 0 because
<span class="math inline">\(\epsilon(\mathbf{x}_0)\)</span> and
<span class="math inline">\(\mathbf{x}_0^T\hat{\boldsymbol{\beta}}\)</span> are uncorrelated.
Why are they uncorrelated? Recall that
<span class="math inline">\(\epsilon(\mathbf{x}_0), \epsilon_1, \ldots, \epsilon_n\)</span> are
uncorrelated. Also, recall that
<span class="math inline">\(\hat{\boldsymbol{\beta}}=(\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{y}\)</span>.
Since <span class="math inline">\(\mathbf{y}=[Y_1,Y_2,\ldots,Y_n]\)</span> and
<span class="math inline">\(Y_i=\mathbf{x}_i^T\boldsymbol{\beta} + \epsilon_i\)</span> for
<span class="math inline">\(i=1,2,\ldots,n\)</span>, the “randomness” of
<span class="math inline">\(\mathbf{x}_0^T\hat{\boldsymbol{\beta}}\)</span> comes from
<span class="math inline">\(\epsilon_1, \epsilon_2, \ldots, \epsilon_n\)</span>. Since
<span class="math inline">\(\epsilon(\mathbf{x}_0)\)</span> is uncorrelated with
<span class="math inline">\(\epsilon_1, \epsilon_2, \ldots, \epsilon_n\)</span>, we conclude
that <span class="math inline">\(\epsilon(\mathbf{x}_0)\)</span> and
<span class="math inline">\(\mathbf{x}_0^T\hat{\boldsymbol{\beta}}\)</span> are uncorrelated,
so their covariance is zero. Thus, we have</p>
<p><span class="math display" id="eq:var-pred-error4">\[
\begin{aligned}
\mathrm{var}\left(Y(\mathbf{x}_0)-\hat{Y}(\mathbf{x}_0)\right)
=\mathrm{var}\left(\epsilon(\mathbf{x}_0)\right)+\mathrm{var}(\mathbf{x}_0^T \hat{\boldsymbol{\beta}}) .
\end{aligned}
\tag{6.16}
\]</span> From our assumptions in Section
<a href="inference.html#properties-betahat">6.3</a>, we have that
<span class="math inline">\(\mathrm{var}(\epsilon(\mathbf{x}_0))=\sigma^2\)</span>. We
determined in Section <a href="inference.html#mean-response-calculations">6.11.2</a> that
<span class="math display">\[
\mathrm{var}(\mathbf{x}_0^T\hat{\boldsymbol{\beta}})=\sigma^2 \mathbf{x}_0^T (\mathbf{X}^T \mathbf{X})^{-1}\mathbf{x}_0.
\]</span> Using these two facts, we can conclude that <span class="math display" id="eq:var-pred-error5">\[
\begin{aligned}
\mathrm{var}\left(Y(\mathbf{x}_0)-\hat{Y}(\mathbf{x}_0)\right)
&amp;=\sigma^2 + \sigma^2 \mathbf{x}_0^T (\mathbf{X}^T \mathbf{X})^{-1}\mathbf{x}_0\\
&amp;=\sigma^2\left(1 + \mathbf{x}_0^T (\mathbf{X}^T \mathbf{X})^{-1}\mathbf{x}_0\right).\\
\end{aligned}
\tag{6.17}
\]</span> Replacing <span class="math inline">\(\sigma^2\)</span> by the typical estimator
<span class="math inline">\(\hat{\sigma}^2=RSS/(n-p)\)</span> to get the estimated variance of
the prediction error and taking the square root of the
estimated variance to get the estimated standard deviation
of the prediction error, we have that <span class="math display">\[
\widehat{\mathrm{sd}}\left(Y(\mathbf{x}_0)-\hat{Y}(\mathbf{x}_0)\right) = \hat{\sigma}\sqrt{1 + \mathbf{x}_0^T (\mathbf{X}^T \mathbf{X})^{-1}\mathbf{x}_0}.
\]</span></p>

</div>
</div>
</div>



</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-bonferroni1936" class="csl-entry">
Bonferroni, Carlo. 1936. <span>“Teoria Statistica Delle Classi e Calcolo Delle Probabilita.”</span> <em>Pubblicazioni Del R Istituto Superiore Di Scienze Economiche e Commericiali Di Firenze</em> 8: 3–62.
</div>
<div id="ref-boole" class="csl-entry">
Boole, George. 1847. <em>The Mathematical Analysis of Logic</em>. Philosophical Library.
</div>
<div id="ref-R-api2lm" class="csl-entry">
French, Joshua P. 2023. <em>Api2lm: Functions and Data Sets for the Book "a Progressive Introduction to Linear Models"</em>. <a href="https://CRAN.R-project.org/package=api2lm">https://CRAN.R-project.org/package=api2lm</a>.
</div>
<div id="ref-R-palmerpenguins" class="csl-entry">
Horst, Allison, Alison Hill, and Kristen Gorman. 2022. <em>Palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data</em>. <a href="https://allisonhorst.github.io/palmerpenguins/">https://allisonhorst.github.io/palmerpenguins/</a>.
</div>
<div id="ref-alsm2005" class="csl-entry">
Kutner, Michael H, Christopher J Nachtsheim, John Neter, and William Li. 2005. <em>Applied Linear Statistical Models, 5th Edition</em>. McGraw-Hill/Irwin, New York.
</div>
<div id="ref-bon_vs_scheffe" class="csl-entry">
Mi, Jie, and Allan R. Sampson. 1993. <span>“A Comparison of the Bonferroni and Scheffé Bounds.”</span> <em>Journal of Statistical Planning and Inference</em> 36 (1): 101–5. <a href="https://doi.org/10.1016/0378-3758(93)90105-F">https://doi.org/10.1016/0378-3758(93)90105-F</a>.
</div>
<div id="ref-wasserman2004all" class="csl-entry">
Wasserman, Larry. 2004. <em>All of Statistics: A Concise Course in Statistical Inference</em>. Vol. 26. Springer.
</div>
<div id="ref-alr4" class="csl-entry">
Weisberg, Sanford. 2014. <em>Applied Linear Regression</em>. Fourth. Hoboken <span>NJ</span>: Wiley. <a href="http://z.umn.edu/alr4ed">http://z.umn.edu/alr4ed</a>.
</div>
<div id="ref-R-dplyr" class="csl-entry">
Wickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis Vaughan. 2023. <em>Dplyr: A Grammar of Data Manipulation</em>. <a href="https://dplyr.tidyverse.org">https://dplyr.tidyverse.org</a>.
</div>
<div id="ref-workinghotelling" class="csl-entry">
Working, Holbrook, and Harold Hotelling. 1929. <span>“Applications of the Theory of Error to the Interpretation of Trends.”</span> <em>Journal of the American Statistical Association</em> 24 (165A): 73–85. <a href="https://doi.org/10.1080/01621459.1929.10506274">https://doi.org/10.1080/01621459.1929.10506274</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="linear-model-theory.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="overview-of-matrix-facts.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["A-Progessive-Introduction-to-Linear-Models.pdf", "A-Progessive-Introduction-to-Linear-Models.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
